{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview - Why MLOps\n",
    "\n",
    "In this first notebook we will create & deploy a model.  When we leverage a model in the cloud, the data will reside somewhere. We will start off by leveraging the default storage associated with your AML workspace.\n",
    "\n",
    "There is no MLOps, but a model will be successfully deployed for inferencing.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1637081579651
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = 'AML_Automation_ManualRun'\n",
    "training_folder = 'training'\n",
    "conda_yml_file = '../configuration/environment.yml'\n",
    "training_dataset = 'diabetes.csv'\n",
    "model_name = 'diabetes_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "print(training_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.34.0 to work with mm-aml-dev2\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train a model, the dataset needs to be fed to the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ../data/diabetes.csv\n",
      "Uploaded ../data/diabetes.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_dd7040ef89fb48ae9a7a76e9c026ec48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload_files(files=['../data/diabetes.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_yml_file = '../configuration/environment.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../configuration/environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $conda_yml_file\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing training/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/training.py\n",
    "\n",
    "# Import libraries\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "ws = run.experiment.workspace\n",
    "ds = ws.get_default_datastore()\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(ds, 'diabetes-data/*.csv'))\n",
    "diabetes = tab_data_set.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac29b88ac924fafb7b290a9ceb97bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/AML_Automation_ManualRun_1637083115_1714b914?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-dev2-rg/workspaces/mm-aml-dev2&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"AML_Automation_ManualRun_1637083115_1714b914\", \"run_properties\": {\"run_id\": \"AML_Automation_ManualRun_1637083115_1714b914\", \"created_utc\": \"2021-11-16T17:18:35.480981Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"cd4e9261-7177-41b4-8318-af12a7eeeebe\", \"azureml.git.repository_uri\": \"https://github.com/memasanz/AMLHackathonWithMLOps.git\", \"mlflow.source.git.repoURL\": \"https://github.com/memasanz/AMLHackathonWithMLOps.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"3a9c70633f849837db9043f6ff9afab036eebf48\", \"mlflow.source.git.commit\": \"3a9c70633f849837db9043f6ff9afab036eebf48\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-11-16T17:20:40.20437Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=j7bKHCtl9cIT88N53I6xdU4hhfL%2FPTz4pPlNCWD9zr8%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T18%3A44%3A57Z&se=2021-11-17T02%3A54%3A57Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=U%2BRTXY1PgFN8bqE4XFDVZlKdNB8V7N4VX%2F9fEV3N1Hs%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T18%3A44%3A57Z&se=2021-11-17T02%3A54%3A57Z&sp=r\", \"logs/azureml/7432_azureml.log\": \"https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/7432_azureml.log?sv=2019-07-07&sr=b&sig=lQkBku5NLKfXMgNao39tCd90S8wH19ZtcnaDQvjZbNw%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T18%3A44%3A57Z&se=2021-11-17T02%3A54%3A57Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=nqX3nMrzNOZ7t%2Fb3t26FELGlmRbJZsDLdTOI%2FtcackI%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T18%3A44%3A57Z&se=2021-11-17T02%3A54%3A57Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=kO7rgpF00YUrhP2uQW%2BIOk9JiHaCNKju9MtyJw%2Baw7o%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T18%3A44%3A57Z&se=2021-11-17T02%3A54%3A57Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/7432_azureml.log\"]], \"run_duration\": \"0:02:04\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"AML_Automation_ManualRun_1637083115_1714b914\", \"categories\": [0], \"series\": [{\"data\": [0.01]}]}, {\"name\": \"Accuracy\", \"run_id\": \"AML_Automation_ManualRun_1637083115_1714b914\", \"categories\": [0], \"series\": [{\"data\": [0.774]}]}, {\"name\": \"AUC\", \"run_id\": \"AML_Automation_ManualRun_1637083115_1714b914\", \"categories\": [0], \"series\": [{\"data\": [0.8484934573859395]}]}], \"run_logs\": \"2021-11-16 17:20:22,632|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2021-11-16 17:20:22,632|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2021-11-16 17:20:22,633|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-11-16 17:20:22,633|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-11-16 17:20:23,051|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fdc3ff0b268> for run source azureml.scriptrun\\n2021-11-16 17:20:23,052|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-11-16 17:20:23,052|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-11-16 17:20:23,053|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-11-16 17:20:23,063|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-11-16 17:20:23,063|azureml.core.authentication|DEBUG|Time to expire 1814291.936394 seconds\\n2021-11-16 17:20:23,063|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-11-16 17:20:23,063|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:23,277|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-11-16 17:20:23,277|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-11-16 17:20:23,353|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:23,354|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'cd4e9261-7177-41b4-8318-af12a7eeeebe', 'azureml.git.repository_uri': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '3a9c70633f849837db9043f6ff9afab036eebf48', 'mlflow.source.git.commit': '3a9c70633f849837db9043f6ff9afab036eebf48', 'azureml.git.dirty': 'True'}\\n2021-11-16 17:20:23,354|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-11-16 17:20:23,354|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-11-16 17:20:23,354|azureml.WorkerPool|DEBUG|[START]\\n2021-11-16 17:20:23,354|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-11-16 17:20:23,354|azureml.RunStatusContext|DEBUG|[START]\\n2021-11-16 17:20:23,354|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-11-16 17:20:23,354|azureml.MetricsClient|DEBUG|[START]\\n2021-11-16 17:20:23,354|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-11-16 17:20:23,355|azureml.ContentUploader|DEBUG|[START]\\n2021-11-16 17:20:23,355|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2021-11-16 17:20:23,356|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2021-11-16 17:20:23,356|azureml.TrackFolders|DEBUG|[START]\\n2021-11-16 17:20:23,356|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-11-16 17:20:23,356|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-11-16 17:20:23,356|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914\\n2021-11-16 17:20:23,356|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-11-16 17:20:23,356|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914\\n2021-11-16 17:20:23,365|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-11-16 17:20:23,366|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-11-16 17:20:23,636|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:23,810|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/7432_azureml.log path: /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/7432_azureml.log\\n2021-11-16 17:20:23,811|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-11-16 17:20:23,812|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:23,812|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2021-11-16 17:20:24,145|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-11-16 17:20:24,146|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-11-16 17:20:24,146|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-11-16 17:20:24,146|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,146|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,147|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,147|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,147|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,147|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,147|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,180|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-11-16 17:20:24,180|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-11-16 17:20:24,308|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:24,309|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': 'cd4e9261-7177-41b4-8318-af12a7eeeebe', 'azureml.git.repository_uri': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '3a9c70633f849837db9043f6ff9afab036eebf48', 'mlflow.source.git.commit': '3a9c70633f849837db9043f6ff9afab036eebf48', 'azureml.git.dirty': 'True'}\\n2021-11-16 17:20:24,309|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-11-16 17:20:24,309|azureml.data.datastore_client|DEBUG|Getting default datastore for provided workspace\\n2021-11-16 17:20:24,309|azureml.data.datastore_client|INFO|<azureml.core.authentication.AzureMLTokenAuthentication object at 0x7fdc3febeb70>\\n2021-11-16 17:20:24,607|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-11-16 17:20:24,608|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-11-16 17:20:24,608|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-11-16 17:20:24,609|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,611|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,618|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,619|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,620|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,620|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:24,620|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westus2.api.azureml.ms.\\n2021-11-16 17:20:30,446|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-11-16 17:20:30,446|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-11-16 17:20:30,447|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-11-16 17:20:30,507|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914|INFO|complete is not setting status for submitted runs.\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-11-16 17:20:30,508|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-11-16 17:20:30,509|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-11-16 17:20:30,509|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-11-16 17:20:30,509|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2021-11-16 17:20:30,509|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:30,509|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-11-16 17:20:30,509|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-11-16 17:20:30,510|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-11-16 17:20:30,510|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-11-16 17:20:30,510|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-11-16 17:20:30,510|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-11-16 17:20:30,510|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2021-11-16 17:20:30,510|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:30,511|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-11-16 17:20:30,511|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-11-16 17:20:30,511|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-11-16 17:20:30,761|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:30,761|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-11-16 17:20:30,761|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:30,761|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 0.0003147125244140625 seconds.\\n\\n2021-11-16 17:20:30,761|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-11-16 17:20:30,761|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-11-16 17:20:30,761|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-11-16 17:20:30,762|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2021-11-16 17:20:30,803|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:31,012|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:31,012|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-11-16 17:20:31,013|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:31,013|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.00014543533325195312 seconds.\\n\\n2021-11-16 17:20:31,013|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-11-16 17:20:31,013|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-11-16 17:20:31,013|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-11-16 17:20:31,013|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-11-16 17:20:31,084|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:31,085|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2021-11-16 17:20:31,085|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-11-16 17:20:31,184|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-11-16 17:20:31,184|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914\\n2021-11-16 17:20:31,184|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914 to /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914\\n2021-11-16 17:20:31,184|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914\\n2021-11-16 17:20:31,184|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-11-16 17:20:31,184|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-11-16 17:20:31,185|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2021-11-16 17:20:31,185|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2021-11-16 17:20:31,185|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2021-11-16 17:20:31,185|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/diabetes_model.pkl\\n2021-11-16 17:20:31,185|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/diabetes_model.pkl'] in dir ./outputs\\n2021-11-16 17:20:31,185|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2021-11-16 17:20:31,185|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2021-11-16 17:20:31,185|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-11-16 17:20:31,185|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-11-16 17:20:31,355|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:31,356|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2021-11-16 17:20:31,357|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:31,357|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2021-11-16 17:20:31,357|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2021-11-16 17:20:31,358|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2021-11-16 17:20:31,358|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2021-11-16 17:20:31,358|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2021-11-16 17:20:31,358|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-11-16 17:20:31,459|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/outputs/diabetes_model.pkl with size 964, file size 964.\\n2021-11-16 17:20:31,608|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:31,609|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2021-11-16 17:20:31,609|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:31,609|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 9.703636169433594e-05 seconds.\\n\\n2021-11-16 17:20:31,609|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2021-11-16 17:20:31,609|azureml.TrackFolders|DEBUG|[STOP]\\n2021-11-16 17:20:31,609|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2021-11-16 17:20:31,609|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2021-11-16 17:20:31,609|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2021-11-16 17:20:31,610|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-11-16 17:20:31,611|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-11-16 17:20:31,795|azureml._SubmittedRun#AML_Automation_ManualRun_1637083115_1714b914.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-11-16 17:20:31,842|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2021-11-16 17:20:31,894|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess.log\\n2021-11-16 17:20:31,894|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-11-16 17:20:31,895|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:31,895|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2021-11-16 17:20:31,895|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-11-16 17:20:31,896|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:31,896|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2021-11-16 17:20:31,902|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-11-16 17:20:31,907|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:31,908|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2021-11-16 17:20:31,908|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2021-11-16 17:20:31,908|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,915|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,916|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,916|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,917|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2021-11-16 17:20:31,918|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2021-11-16 17:20:31,918|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2021-11-16 17:20:31,918|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,923|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,924|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,924|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,924|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,925|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,925|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2021-11-16 17:20:31,926|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2021-11-16 17:20:31,926|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result)].\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-11-16 17:20:31,927|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:32,178|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2021-11-16 17:20:32,178|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2021-11-16 17:20:32,178|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2021-11-16 17:20:32,178|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 4_result.\\n1 tasks left. Current duration of flush 0.0005793571472167969 seconds.\\n\\n2021-11-16 17:20:32,178|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AML_Automation_ManualRun_1637083115_1714b914',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-11-16T17:20:21.914056Z',\n",
       " 'endTimeUtc': '2021-11-16T17:20:40.20437Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'cd4e9261-7177-41b4-8318-af12a7eeeebe',\n",
       "  'azureml.git.repository_uri': 'https://github.com/memasanz/AMLHackathonWithMLOps.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/memasanz/AMLHackathonWithMLOps.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '3a9c70633f849837db9043f6ff9afab036eebf48',\n",
       "  'mlflow.source.git.commit': '3a9c70633f849837db9043f6ff9afab036eebf48',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'ipykernel',\n",
       "      'matplotlib',\n",
       "      'pandas',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'pyarrow']}],\n",
       "     'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True}},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=H%2FOvlVCEuG6bzBY81V0Lhu9C3HztA2knr9d8MMmtcIE%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T17%3A10%3A41Z&se=2021-11-17T01%3A20%3A41Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=ItP0NPzlKNd9%2FJ2A%2FVFpIZ0VeD0ZX6i%2BN9cbZMP9hdU%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T17%3A10%3A41Z&se=2021-11-17T01%3A20%3A41Z&sp=r',\n",
       "  'logs/azureml/7432_azureml.log': 'https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/7432_azureml.log?sv=2019-07-07&sr=b&sig=%2B9ax2VSqYe0RbCkicKn04EiP9VRn4LmZklht4b%2BTY%2BM%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T17%3A10%3A34Z&se=2021-11-17T01%3A20%3A34Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=IcV9BHPJe%2BWZNmkhIn3B08d4e1nD8fqS%2Fhv2cPxgGg4%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T17%3A10%3A34Z&se=2021-11-17T01%3A20%3A34Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmamldev24709630538.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1637083115_1714b914/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=o1WcgPgu%2FObzKSR%2FCqxm%2FH8demOsbk%2B4rne8B6dYVEY%3D&skoid=b7a3bef5-d355-4fee-9d06-a4a027869af0&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-16T15%3A23%3A14Z&ske=2021-11-17T23%3A33%3A14Z&sks=b&skv=2019-07-07&st=2021-11-16T17%3A10%3A34Z&se=2021-11-17T01%3A20%3A34Z&sp=r'},\n",
       " 'submittedBy': 'Megan Masanz'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", conda_yml_file)\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='training.py',\n",
    "                                environment=env) \n",
    "\n",
    "# submit the experiment run\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "\n",
    "# Show the running experiment run in the notebook widget\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Rate 0.01\n",
      "Accuracy 0.774\n",
      "AUC 0.8484934573859395\n",
      "\n",
      "\n",
      "azureml-logs/60_control_log.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "logs/azureml/7432_azureml.log\n",
      "logs/azureml/dataprep/backgroundProcess.log\n",
      "logs/azureml/dataprep/backgroundProcess_Telemetry.log\n",
      "outputs/diabetes_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t AUC : 0.848485994328076\n",
      "\t AUC : 0.848485994328076\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 9\n",
      "\t Model Type : Logistic regression\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 8\n",
      "\t Model Type : Logistic Regresssion\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 7\n",
      "\t Model Type : Logistic regression\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 6\n",
      "\t Model Type : Logistic Regresssion\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 5\n",
      "\t Model Type : Logistic regression\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 4\n",
      "\t Model Type : Logistic Regresssion\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 3\n",
      "\t Model Type : Logistic regression\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 2\n",
      "\t Model Type : Logistic Regresssion\n",
      "\n",
      "\n",
      "memasanz-diabetes_code-a-thon-model version: 1\n",
      "\t Model Type : Logistic Regresssion\n",
      "\n",
      "\n",
      "memasanzdiabetes_model version: 1\n",
      "\t Model Type : Logistic Regresssion\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'AUC':run.get_metrics()['AUC']},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_diabetes.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 2\n"
     ]
    }
   ],
   "source": [
    "model = ws.models[model_name]\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-11-16 17:21:43+00:00 Creating Container Registry if not exists.\n",
      "2021-11-16 17:21:44+00:00 Registering the environment.\n",
      "2021-11-16 17:21:45+00:00 Use the existing image.\n",
      "2021-11-16 17:21:45+00:00 Generating deployment configuration.\n",
      "2021-11-16 17:21:46+00:00 Submitting deployment to compute.\n",
      "2021-11-16 17:21:48+00:00 Checking the status of deployment diabetes-service..\n",
      "2021-11-16 17:23:39+00:00 Checking the status of inference endpoint diabetes-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment, Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "service_env = Environment(name='service-env')\n",
    "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\n",
    "for package in python_packages:\n",
    "    service_env.python.conda_dependencies.add_pip_package(package)\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"diabetes-service\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Web service\n",
    "With the service deployed, now you can consume it from a client application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "{\"data\": [[2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]]}\n",
      "not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "print(input_json)\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
