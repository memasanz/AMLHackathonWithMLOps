{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview - Why MLOps\n",
    "\n",
    "In this first notebook we will create & deploy a model.  When we leverage a model in the cloud, the data will reside somewhere. We will start off by leveraging the default storage associated with your AML workspace.\n",
    "\n",
    "There is no MLOps, but a model will be successfully deployed for inferencing.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1637081579651
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = 'AML_Automation_ManualRun'\n",
    "training_folder = 'training'\n",
    "conda_yml_file = '../configuration/environment.yml'\n",
    "training_dataset = 'diabetes.csv'\n",
    "model_name = 'diabetes_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "print(training_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.37.0 to work with mm-aml-dev-ops\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train a model, the dataset needs to be fed to the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ../data/diabetes.csv\n",
      "Uploaded ../data/diabetes.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_bbff299931164f5fbfd7cd8257744bc2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "\n",
    "default_ds.upload_files(files=['../data/diabetes.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_yml_file = '../configuration/environment.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../configuration/environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $conda_yml_file\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training/training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/training.py\n",
    "\n",
    "# Import libraries\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "ws = run.experiment.workspace\n",
    "ds = ws.get_default_datastore()\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(ds, 'diabetes-data/*.csv'))\n",
    "diabetes = tab_data_set.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print('****************')\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print('****************')\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c192026f3644ca9a5e504333292bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/AML_Automation_ManualRun_1643586195_31ce55ae?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-dev-ops-rg/workspaces/mm-aml-dev-ops&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"AML_Automation_ManualRun_1643586195_31ce55ae\", \"run_properties\": {\"run_id\": \"AML_Automation_ManualRun_1643586195_31ce55ae\", \"created_utc\": \"2022-01-30T23:43:15.885795Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"83984cb9-d5e2-4c9f-a240-5e11197b6217\", \"azureml.git.repository_uri\": \"https://github.com/memasanz/AMLHackathonWithMLOps.git\", \"mlflow.source.git.repoURL\": \"https://github.com/memasanz/AMLHackathonWithMLOps.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"50315573bf46439a76a891a01dc41f3e719db2ad\", \"mlflow.source.git.commit\": \"50315573bf46439a76a891a01dc41f3e719db2ad\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-01-30T23:43:41.440244Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=VBi3wDhPb8E51vFyewXJFbS6vebaK1j3ILRdwuoibDw%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-31T01%3A48%3A32Z&se=2022-01-31T09%3A58%3A32Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=y2wzwihOlUz9yC9SWJmxYq2Fy6SwgSuTpXvTjoVSWcA%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-31T01%3A48%3A32Z&se=2022-01-31T09%3A58%3A32Z&sp=r\", \"logs/azureml/25397_azureml.log\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/25397_azureml.log?sv=2019-07-07&sr=b&sig=i73X57Q27wabgEve7TOMh%2F9uOKJHwwVyZlNA8rEYJvY%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-31T01%3A48%3A32Z&se=2022-01-31T09%3A58%3A32Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=wfJp8DrJVROg7sbNpEQcid17aDLg9PT95mIkIcpiGM4%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-31T01%3A48%3A33Z&se=2022-01-31T09%3A58%3A33Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=mMaY%2BuaDZAIB4ByESN9E%2FkNctF15ZEMDl33NkuXHiy0%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-31T01%3A48%3A33Z&se=2022-01-31T09%3A58%3A33Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/25397_azureml.log\"]], \"run_duration\": \"0:00:25\", \"run_number\": \"2\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"AML_Automation_ManualRun_1643586195_31ce55ae\", \"categories\": [0], \"series\": [{\"data\": [0.01]}]}, {\"name\": \"Accuracy\", \"run_id\": \"AML_Automation_ManualRun_1643586195_31ce55ae\", \"categories\": [0], \"series\": [{\"data\": [0.774]}]}, {\"name\": \"AUC\", \"run_id\": \"AML_Automation_ManualRun_1643586195_31ce55ae\", \"categories\": [0], \"series\": [{\"data\": [0.848485994328076]}]}], \"run_logs\": \"2022-01-30 23:43:18,587|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2022-01-30 23:43:18,595|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2022-01-30 23:43:18,595|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2022-01-30 23:43:18,595|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2022-01-30 23:43:19,329|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f1200f55400> for run source azureml.scriptrun\\n2022-01-30 23:43:19,330|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-01-30 23:43:19,330|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-01-30 23:43:19,336|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-01-30 23:43:19,346|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2022-01-30 23:43:19,346|azureml.core.authentication|DEBUG|Time to expire 1814395.6538 seconds\\n2022-01-30 23:43:19,346|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2022-01-30 23:43:19,346|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:19,347|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:19,347|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:19,347|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:19,347|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:19,347|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:19,347|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:20,410|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-01-30 23:43:20,410|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-01-30 23:43:20,481|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:20,482|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '83984cb9-d5e2-4c9f-a240-5e11197b6217', 'azureml.git.repository_uri': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '50315573bf46439a76a891a01dc41f3e719db2ad', 'mlflow.source.git.commit': '50315573bf46439a76a891a01dc41f3e719db2ad', 'azureml.git.dirty': 'True'}\\n2022-01-30 23:43:20,482|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-01-30 23:43:20,483|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2022-01-30 23:43:20,483|azureml.WorkerPool|DEBUG|[START]\\n2022-01-30 23:43:20,483|azureml.SendRunKillSignal|DEBUG|[START]\\n2022-01-30 23:43:20,483|azureml.RunStatusContext|DEBUG|[START]\\n2022-01-30 23:43:20,483|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunContextManager.RunStatusContext|DEBUG|[START]\\n2022-01-30 23:43:20,483|azureml.MetricsClient|DEBUG|[START]\\n2022-01-30 23:43:20,483|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2022-01-30 23:43:20,484|azureml.ContentUploader|DEBUG|[START]\\n2022-01-30 23:43:20,484|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2022-01-30 23:43:20,485|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2022-01-30 23:43:20,485|azureml.TrackFolders|DEBUG|[START]\\n2022-01-30 23:43:20,486|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2022-01-30 23:43:20,486|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2022-01-30 23:43:20,486|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae\\n2022-01-30 23:43:20,486|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-01-30 23:43:20,486|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae\\n2022-01-30 23:43:20,488|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-01-30 23:43:20,493|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-01-30 23:43:20,690|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:20,734|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/25397_azureml.log path: /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/25397_azureml.log\\n2022-01-30 23:43:20,735|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-30 23:43:20,736|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:20,737|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2022-01-30 23:43:21,522|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-01-30 23:43:21,522|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-01-30 23:43:21,522|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-01-30 23:43:21,522|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,523|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,523|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,523|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,523|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,524|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,524|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:21,557|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2022-01-30 23:43:21,558|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2022-01-30 23:43:21,612|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:21,613|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': '83984cb9-d5e2-4c9f-a240-5e11197b6217', 'azureml.git.repository_uri': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'mlflow.source.git.repoURL': 'https://github.com/memasanz/AMLHackathonWithMLOps.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '50315573bf46439a76a891a01dc41f3e719db2ad', 'mlflow.source.git.commit': '50315573bf46439a76a891a01dc41f3e719db2ad', 'azureml.git.dirty': 'True'}\\n2022-01-30 23:43:21,613|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2022-01-30 23:43:21,613|azureml.data.datastore_client|DEBUG|Getting default datastore for provided workspace\\n2022-01-30 23:43:21,613|azureml.data.datastore_client|INFO|<azureml.core.authentication.AzureMLTokenAuthentication object at 0x7f1200e1d358>\\n2022-01-30 23:43:22,128|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2022-01-30 23:43:22,129|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2022-01-30 23:43:22,129|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2022-01-30 23:43:22,130|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:22,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:22,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:22,132|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:22,133|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:22,133|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:22,133|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2022-01-30 23:43:28,885|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-01-30 23:43:28,886|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2022-01-30 23:43:28,886|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-01-30 23:43:28,989|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae|INFO|complete is not setting status for submitted runs.\\n2022-01-30 23:43:28,989|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2022-01-30 23:43:28,989|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2022-01-30 23:43:28,989|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2022-01-30 23:43:28,990|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2022-01-30 23:43:28,990|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-01-30 23:43:28,990|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-01-30 23:43:28,990|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2022-01-30 23:43:28,991|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2022-01-30 23:43:28,991|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-01-30 23:43:28,991|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2022-01-30 23:43:28,991|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2022-01-30 23:43:28,991|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 3.\\n2022-01-30 23:43:28,991|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:28,992|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2022-01-30 23:43:28,992|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2022-01-30 23:43:28,992|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 3 values.\\n2022-01-30 23:43:28,992|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2022-01-30 23:43:28,992|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:28,993|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2022-01-30 23:43:28,993|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2022-01-30 23:43:28,993|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2022-01-30 23:43:28,993|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2022-01-30 23:43:28,993|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2022-01-30 23:43:29,000|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2022-01-30 23:43:29,000|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:29,001|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2022-01-30 23:43:29,001|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:29,001|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2022-01-30 23:43:29,001|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2022-01-30 23:43:29,001|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2022-01-30 23:43:29,001|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2022-01-30 23:43:29,002|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0__log_batch_v2)].\\n2022-01-30 23:43:29,234|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:29,252|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:29,252|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2022-01-30 23:43:29,252|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:29,253|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Waiting on task: 0__log_batch_v2.\\n1 tasks left. Current duration of flush 0.00010466575622558594 seconds.\\n\\n2022-01-30 23:43:29,253|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2022-01-30 23:43:29,253|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2022-01-30 23:43:29,253|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2022-01-30 23:43:29,253|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2022-01-30 23:43:29,300|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:30,741|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-01-30 23:43:30,741|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-01-30 23:43:30,983|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:31,018|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess_Telemetry.log path: /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess_Telemetry.log\\n2022-01-30 23:43:31,062|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess.log path: /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess.log\\n2022-01-30 23:43:31,062|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-30 23:43:31,063|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:31,063|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2022-01-30 23:43:31,066|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-30 23:43:31,067|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:31,067|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2022-01-30 23:43:31,067|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-30 23:43:31,070|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:31,070|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2022-01-30 23:43:34,303|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2022-01-30 23:43:34,382|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: [], excluding []\\n2022-01-30 23:43:34,383|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-01-30 23:43:34,495|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2022-01-30 23:43:34,495|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae\\n2022-01-30 23:43:34,495|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae to /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/AML_Automation_ManualRun_1643586195_31ce55ae\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2022-01-30 23:43:34,496|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/diabetes_model.pkl\\n2022-01-30 23:43:34,496|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/diabetes_model.pkl'] in dir ./outputs\\n2022-01-30 23:43:34,496|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2022-01-30 23:43:34,496|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2022-01-30 23:43:34,496|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2022-01-30 23:43:34,496|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2022-01-30 23:43:34,673|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2022-01-30 23:43:34,673|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2022-01-30 23:43:34,673|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:34,674|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2022-01-30 23:43:34,674|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2022-01-30 23:43:34,676|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2022-01-30 23:43:34,679|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2022-01-30 23:43:34,679|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2022-01-30 23:43:34,679|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2022-01-30 23:43:34,732|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/outputs/diabetes_model.pkl with size 964, file size 964.\\n2022-01-30 23:43:34,930|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:34,930|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2022-01-30 23:43:34,930|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:34,930|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 0.00010323524475097656 seconds.\\n\\n2022-01-30 23:43:34,930|azureml._SubmittedRun#AML_Automation_ManualRun_1643586195_31ce55ae.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2022-01-30 23:43:34,930|azureml.TrackFolders|DEBUG|[STOP]\\n2022-01-30 23:43:34,930|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2022-01-30 23:43:34,930|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2022-01-30 23:43:34,931|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2022-01-30 23:43:34,931|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-30 23:43:34,932|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:34,932|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2022-01-30 23:43:34,936|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2022-01-30 23:43:34,936|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,936|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,936|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,937|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,937|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,937|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,938|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,938|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,938|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,939|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,939|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,939|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,940|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,940|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,940|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,940|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,941|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,941|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,941|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,942|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,942|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,942|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,942|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2022-01-30 23:43:34,944|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2022-01-30 23:43:34,945|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result|DEBUG|Using basic handler - no exception handling\\n2022-01-30 23:43:34,945|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 5_result to queue of approximate size: 5\\n2022-01-30 23:43:34,945|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2022-01-30 23:43:34,946|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2022-01-30 23:43:34,946|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2022-01-30 23:43:34,948|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2022-01-30 23:43:34,948|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result), AsyncTask(5_result)].\\n2022-01-30 23:43:34,948|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-30 23:43:34,949|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:35,200|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[START]\\n2022-01-30 23:43:35,200|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2022-01-30 23:43:35,200|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[STOP]\\n2022-01-30 23:43:35,200|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 5_result.\\n1 tasks left. Current duration of flush 0.0012426376342773438 seconds.\\n\\n2022-01-30 23:43:35,200|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.37.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AML_Automation_ManualRun_1643586195_31ce55ae',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2022-01-30T23:43:16.670509Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '83984cb9-d5e2-4c9f-a240-5e11197b6217',\n",
       "  'azureml.git.repository_uri': 'https://github.com/memasanz/AMLHackathonWithMLOps.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/memasanz/AMLHackathonWithMLOps.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '50315573bf46439a76a891a01dc41f3e719db2ad',\n",
       "  'mlflow.source.git.commit': '50315573bf46439a76a891a01dc41f3e719db2ad',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': 'Autosave_2022-01-28T15:27:10Z_1dfc3ae2',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'ipykernel',\n",
       "      'matplotlib',\n",
       "      'pandas',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'pyarrow']}],\n",
       "     'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20211124.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=T25RKcfuFpbNm72b7yMAwRi0KvS%2FkiWM5tLBzP9hapM%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-30T23%3A33%3A33Z&se=2022-01-31T07%3A43%3A33Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=tp7TThDfjHJ%2Fez8lxs6FNkJ4bP%2F7UjP%2BURLpijrmn%2BI%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-30T23%3A33%3A33Z&se=2022-01-31T07%3A43%3A33Z&sp=r',\n",
       "  'logs/azureml/25397_azureml.log': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/25397_azureml.log?sv=2019-07-07&sr=b&sig=haay3Stg%2BcNXV0Bx72UW9dh8M30J100rFQ89QZAamRE%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-30T23%3A33%3A33Z&se=2022-01-31T07%3A43%3A33Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=XIGUz14SaTEJT3yMXXntbiYvKMFZgjgbLzs7GV0WKSg%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-30T23%3A33%3A33Z&se=2022-01-31T07%3A43%3A33Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmamldevops9020263291.blob.core.windows.net/azureml/ExperimentRun/dcid.AML_Automation_ManualRun_1643586195_31ce55ae/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=hhJOnZ188qiRha755CRVeHLBC7Qms%2BdQbNlwvTB%2F2ts%3D&skoid=6e96e716-19f5-4664-a48c-bccfc5f7e7f7&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-01-30T20%3A30%3A53Z&ske=2022-02-01T04%3A40%3A53Z&sks=b&skv=2019-07-07&st=2022-01-30T23%3A33%3A33Z&se=2022-01-31T07%3A43%3A33Z&sp=r'},\n",
       " 'submittedBy': 'Megan Masanz'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", conda_yml_file)\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='training.py',\n",
    "                                environment=env) \n",
    "\n",
    "# submit the experiment run\n",
    "\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "\n",
    "# Show the running experiment run in the notebook widget\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Rate 0.01\n",
      "Accuracy 0.774\n",
      "AUC 0.848485994328076\n",
      "\n",
      "\n",
      "azureml-logs/60_control_log.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "logs/azureml/25397_azureml.log\n",
      "logs/azureml/dataprep/backgroundProcess.log\n",
      "logs/azureml/dataprep/backgroundProcess_Telemetry.log\n",
      "outputs/diabetes_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 2\n",
      "\t AUC : 0.848485994328076\n",
      "\t AUC : 0.848485994328076\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 12\n",
      "\t AUC : 0.8484934573859395\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 11\n",
      "\t AUC : 0.848485994328076\n",
      "\t AUC : 0.848485994328076\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 10\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.848485994328076\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 9\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.848485994328076\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 8\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.848485994328076\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 7\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 6\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 5\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 4\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 3\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 2\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model_remote version: 1\n",
      "\t AUC : 0.2\n",
      "\t AUC : 0.8484934573859395\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t AUC : 0.848485994328076\n",
      "\t AUC : 0.848485994328076\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'AUC':run.get_metrics()['AUC']},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a folder for the deployment files\n",
    "deployment_folder = './service'\n",
    "os.makedirs(deployment_folder, exist_ok=True)\n",
    "print(deployment_folder, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = 'score_diabetes.py'\n",
    "script_path = os.path.join(deployment_folder,script_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_path\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 1\n"
     ]
    }
   ],
   "source": [
    "model = ws.models[model_name]\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-01-28 15:31:08+00:00 Creating Container Registry if not exists..\n",
      "2022-01-28 15:41:08+00:00 Registering the environment..\n",
      "2022-01-28 15:41:12+00:00 Building image..\n",
      "2022-01-28 15:46:54+00:00 Generating deployment configuration.\n",
      "2022-01-28 15:46:55+00:00 Submitting deployment to compute..\n",
      "2022-01-28 15:47:00+00:00 Checking the status of deployment diabetes-service-local-training..\n",
      "2022-01-28 15:49:01+00:00 Checking the status of inference endpoint diabetes-service-local-training.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment, Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Configure the scoring environment\n",
    "service_env = Environment(name='service-env')\n",
    "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\n",
    "for package in python_packages:\n",
    "    service_env.python.conda_dependencies.add_pip_package(package)\n",
    "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
    "                                   entry_script=script_file,\n",
    "                                   environment=service_env)\n",
    "\n",
    "# Configure the web service container\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "\n",
    "# Deploy the model as a service\n",
    "print('Deploying model...')\n",
    "service_name = \"diabetes-service-local-training\"\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Web service\n",
    "With the service deployed, now you can consume it from a client application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "http://cc70226a-aa99-417a-910f-16e35ce50768.eastus.azurecontainer.io/score\n",
      "{\"data\": [[2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]]}\n",
      "[\"not-diabetic\"]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "\n",
    "#get service endpoint\n",
    "service = Webservice(workspace=ws, name='diabetes-service-local-training')\n",
    "print(service.state)\n",
    "url = service.scoring_uri\n",
    "print(url)\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "\n",
    "def MakePrediction():\n",
    "    endpoint_url = url\n",
    "    x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "    input_json = json.dumps({\"data\": x_new})\n",
    "    print(input_json)\n",
    "    body = input_json\n",
    "    r = requests.post(endpoint_url, headers=headers, data=body)\n",
    "    return (r.json())\n",
    "\n",
    "\n",
    "results = MakePrediction()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
