{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1482d0b",
   "metadata": {},
   "source": [
    "## MLOps with Azure ML Pipelines\n",
    "\n",
    "ML Pipeline - Training & Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ed2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_env_name = \"experiment_env\"\n",
    "experiment_folder = 'exp_pipeline'\n",
    "dataset_prefix_name = 'exp'\n",
    "cluster_name = \"mm-cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23e496",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8006de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17a44c",
   "metadata": {},
   "source": [
    "Connect to the workspace and create a cluster for running the AML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f59e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "# Connect to AML Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800a4a0",
   "metadata": {},
   "source": [
    "## Create Run configuration\n",
    "The RunConfiguration defines the environment used across all the python steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e64e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda_yml_file = '../configuration/environment.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c585faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../configuration/environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $conda_yml_file\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14582efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", conda_yml_file)\n",
    "\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.docker.use_docker = True\n",
    "run_config.environment = env\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142a17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1db661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_env'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7778ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(registered_env_name, conda_yml_file)\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, registered_env_name)\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51624940",
   "metadata": {},
   "source": [
    "## Define Output datasets\n",
    "\n",
    "Represent how to copy the output of a run and be promoted as a FileDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20c4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_raw_data       = OutputFileDatasetConfig(name='Exp_Raw_Data', destination=(default_ds, dataset_prefix_name + '_raw_data/{run-id}')).read_delimited_files().register_on_complete(name= dataset_prefix_name + '_Raw_Data')\n",
    "exp_training_data  = OutputFileDatasetConfig(name='Exp_Training_Data', destination=(default_ds, dataset_prefix_name + '_training_data/{run-id}')).read_delimited_files().register_on_complete(name=dataset_prefix_name + '_Training_Data')\n",
    "exp_testing_data   = OutputFileDatasetConfig(name='Exp_Testing_Data', destination=(default_ds, dataset_prefix_name + '_testing_data/{run-id}')).read_delimited_files().register_on_complete(name=dataset_prefix_name + '_Testing_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22765c",
   "metadata": {},
   "source": [
    "## Define Pipeline Data\n",
    "\n",
    "we will register model artifacts in the final step if our model performs better than the current mode.  Represents intermediate data in an Azure Machine Learning pipeline.\n",
    "\n",
    "Data used in pipeline can be produced by one step and consumed in another step by providing a PipelineData object as an output of one step and an input of one or more subsequent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170a8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trained_model_pipeline_data = PipelineData(name='exp_trained_model_pipeline_data', datastore=default_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37944cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./exp_pipeline/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/get_data.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Get data from and register in AML workspace\")\n",
    "parser.add_argument('--exp_raw_data', dest='exp_raw_data', required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_raw_dataset = args.exp_raw_data\n",
    "\n",
    "#Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "#Connect to default data store\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "\n",
    "raw_df = tab_data_set.to_pandas_dataframe()\n",
    "\n",
    "#Make directory on mounted storage\n",
    "os.makedirs(exp_raw_dataset, exist_ok=True)\n",
    "\n",
    "#Upload modified dataframe\n",
    "raw_df.to_csv(os.path.join(exp_raw_dataset, 'exp_raw_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87df8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./exp_pipeline/split.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/split.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Split raw data into train/test and scale appropriately\")\n",
    "\n",
    "parser.add_argument('--exp_training_data', dest='exp_training_data', required=True)\n",
    "parser.add_argument('--exp_testing_data', dest='exp_testing_data', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_training_data = args.exp_training_data\n",
    "exp_testing_data = args.exp_testing_data\n",
    "\n",
    "\n",
    "#Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "# Read input dataset to pandas dataframe\n",
    "raw_datset = current_run.input_datasets['Exp_Raw_Data']\n",
    "raw_df = raw_datset.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "for col in raw_df.columns:\n",
    "    missing = raw_df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    if num_missing > 0:  \n",
    "        raw_df['quality_{}_ismissing'.format(col)] = missing\n",
    "\n",
    "\n",
    "print(raw_df.columns)\n",
    "\n",
    "#Split data into training set and test set\n",
    "df_train, df_test = train_test_split(raw_df, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save train data to both train and test (reflects the usage pattern in this sample. Note: test/train sets are typically distinct data).\n",
    "os.makedirs(exp_training_data, exist_ok=True)\n",
    "os.makedirs(exp_testing_data, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(os.path.join(exp_training_data, 'exp_training_data.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(exp_testing_data, 'exp_testing_data.csv'), index=False)\n",
    "\n",
    "# Save scaler to PipelineData and outputs for record-keeping\n",
    "#os.makedirs('./outputs', exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8959aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./exp_pipeline/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/train.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Train Logistic Regression model\")\n",
    "parser.add_argument('--exp_trained_model_pipeline_data', dest='exp_trained_model_pipeline_data', required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_trained_model_pipeline_data = args.exp_trained_model_pipeline_data\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "# Read input dataset to pandas dataframe\n",
    "X_train_dataset = run.input_datasets['Exp_Training_Data'].to_pandas_dataframe()\n",
    "X_test_dataset = run.input_datasets['Exp_Testing_Data'].to_pandas_dataframe()\n",
    "\n",
    "print(type(X_train_dataset))\n",
    "\n",
    "# Separate features and labels\n",
    "X_train, y_train = X_train_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_train_dataset['Diabetic'].values\n",
    "X_test, y_test   = X_test_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_test_dataset['Diabetic'].values\n",
    "\n",
    "\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "run.parent.log(name='AUC', value=np.float(auc))\n",
    "run.parent.log(name='Accuracy', value=np.float(acc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='./outputs/diabetes_model.pkl')\n",
    "\n",
    "#df_train.to_csv(os.path.join(exp_training_data, 'exp_training_data.csv'), index=False)\n",
    "os.makedirs(exp_trained_model_pipeline_data, exist_ok=True)\n",
    "\n",
    "shutil.copyfile('./outputs/diabetes_model.pkl', os.path.join(exp_trained_model_pipeline_data, 'diabetes_model.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e96bc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./exp_pipeline/evaluate_and_register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/evaluate_and_register.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "parser.add_argument('--exp_trained_model_pipeline_data', type=str, required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_trained_model_pipeline_data = args.exp_trained_model_pipeline_data\n",
    "\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "current_model_AUC = float(metrics['AUC'])\n",
    "current_model_accuracy = float(metrics['Accuracy'])\n",
    "\n",
    "# Get current model from workspace\n",
    "model_name = 'diabetes_model'\n",
    "model_description = 'Diabetes model'\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'AUC': current_model_AUC}\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "# Copy autoencoder training outputs to relative path for registration\n",
    "relative_model_path = 'model_files'\n",
    "run.upload_folder(name=relative_model_path, path=exp_trained_model_pipeline_data)\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    #model = run.register_model(model_name, model_path='model_files', description=model_description, model_framework='sklearn', model_framework_version=tf.__version__, tags=updated_tags, datasets=formatted_datasets, sample_input_dataset = training_dataset)\n",
    "    run.register_model(model_path=relative_model_path, model_name='diabetes_model',\n",
    "                   tags=updated_tags,\n",
    "                   properties={'AUC': current_model_AUC})\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['AUC']) < current_model_AUC:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "        #model = run.register_model(model_name, model_path='model_files', description=model_description, model_framework='Tensorflow/Keras', model_framework_version=tf.__version__, tags=updated_tags, datasets=formatted_datasets, sample_input_dataset = training_dataset)\n",
    "        run.register_model(model_path=relative_model_path, model_name='diabetes_model',\n",
    "                   tags=updated_tags,\n",
    "                   properties={'AUC': current_model_AUC, 'Accuracy': current_model_accuracy})\n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115753b",
   "metadata": {},
   "source": [
    "## Create Pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dfa88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get raw data from registered\n",
    "#Register tabular dataset after retrieval\n",
    "get_data_step = PythonScriptStep(\n",
    "    name='Get Data',\n",
    "    script_name='get_data.py',\n",
    "    arguments =['--exp_raw_data', exp_raw_data],\n",
    "    outputs=[exp_raw_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "#Normalize the raw data using a MinMaxScaler\n",
    "#and then split into test and train datasets\n",
    "split_scale_step = PythonScriptStep(\n",
    "    name='Split  Raw Data',\n",
    "    script_name='split.py',\n",
    "    arguments =['--exp_training_data', exp_training_data,\n",
    "                '--exp_testing_data', exp_testing_data],\n",
    "    inputs=[exp_raw_data.as_input(name='Exp_Raw_Data')],\n",
    "    outputs=[exp_training_data, exp_testing_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "#Train autoencoder using raw data as an input\n",
    "#Raw data will be preprocessed and registered as train/test datasets\n",
    "#Scaler and train autoencoder will be saved out\n",
    "train_model_step = PythonScriptStep(\n",
    "    name='Train',\n",
    "    script_name='train.py',\n",
    "    arguments =['--exp_trained_model_pipeline_data', exp_trained_model_pipeline_data],\n",
    "    inputs=[exp_training_data.as_input(name='Exp_Training_Data'),\n",
    "            exp_testing_data.as_input(name='Exp_Testing_Data'),\n",
    "           ],\n",
    "    outputs=[exp_trained_model_pipeline_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")\n",
    "\n",
    "#Evaluate and register model here\n",
    "#Compare metrics from current model and register if better than current\n",
    "#best model\n",
    "evaluate_and_register_step = PythonScriptStep(\n",
    "    name='Evaluate and Register Model',\n",
    "    script_name='evaluate_and_register.py',\n",
    "    arguments=['--exp_trained_model_pipeline_data', exp_trained_model_pipeline_data],\n",
    "    inputs=[ exp_trained_model_pipeline_data.as_input('exp_trained_model_pipeline_data')],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e261a",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "Create an Azure ML Pipeline by specifying the steps to be executed. Note: based on the dataset dependencies between steps, exection occurs logically such that no step will execute unless all of the necessary input datasets have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "058aa1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[get_data_step, split_scale_step, train_model_step, evaluate_and_register_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c750ca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Get Data [4ee63030][7c067bc7-ef78-45bb-9d0b-c0017ab52a7a], (This step will run and generate new outputs)\n",
      "Created step Split  Raw Data [94048c2f][079abd42-3d10-40a6-9521-bbf3e3ebfbe8], (This step will run and generate new outputs)\n",
      "Created step Train [ebec4b1c][706de45e-1c43-477b-a2ea-32427be37737], (This step will run and generate new outputs)\n",
      "Created step Evaluate and Register Model [79980463][c77d40b6-bbfe-4f5a-a5f8-0051af45ee09], (This step will run and generate new outputs)\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = pipeline.publish(name = 'Exp_Training_Registration_Pipeline',\n",
    "                                     description = 'Pipeline to load/register data from datastore, train, and register the trained model if it performs better than the current best model.',\n",
    "                                     continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d2c85c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun c650cf47-3924-41bf-863b-bb3fdabb8729\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c650cf47-3924-41bf-863b-bb3fdabb8729?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRunId: c650cf47-3924-41bf-863b-bb3fdabb8729\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c650cf47-3924-41bf-863b-bb3fdabb8729?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 7b51b10a-b11a-4d61-abb5-78f809f3eb1a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7b51b10a-b11a-4d61-abb5-78f809f3eb1a?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Get Data ) Status: Running\n",
      "\n",
      "StepRun(Get Data) Execution Summary\n",
      "====================================\n",
      "StepRun( Get Data ) Status: Finished\n",
      "\n",
      "Warnings:\n",
      "This run is using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"\n",
      "{'runId': '7b51b10a-b11a-4d61-abb5-78f809f3eb1a', 'target': 'mm-cluster', 'status': 'Completed', 'startTimeUtc': '2021-11-15T16:28:45.38469Z', 'endTimeUtc': '2021-11-15T16:29:35.017152Z', 'services': {}, 'warnings': [{'message': 'This run is using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"'}], 'properties': {'ContentSnapshotId': 'b18049c8-d927-4fae-bf3d-e95c40d4056e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '7c067bc7-ef78-45bb-9d0b-c0017ab52a7a', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '4ee63030', 'azureml.pipelinerunid': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipeline': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [{'identifier': {'savedId': '882a97b7-8f14-40c8-b924-1181eeae1977', 'registeredId': '6d367798-2f90-42d7-8148-1fcac6a5f063', 'registeredVersion': '61'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'Exp_Raw_Data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'exp_raw_data/7b51b10a-b11a-4d61-abb5-78f809f3eb1a')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"882a97b7-8f14-40c8-b924-1181eeae1977\",\n",
      "    \"name\": \"exp_Raw_Data\",\n",
      "    \"version\": 61,\n",
      "    \"workspace\": \"Workspace.create(name='mm-aml-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-machine-learning-dev-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'get_data.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--exp_raw_data', 'DatasetOutputConfig:Exp_Raw_Data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mm-cluster', 'dataReferences': {}, 'data': {}, 'outputData': {'Exp_Raw_Data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'exp_raw_data/{run-id}'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'exp_Raw_Data', 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"2770d60f-39ae-48fd-8b5a-1d30aa33c5e9\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"0f78a3d3-2d9a-4a6f-9acd-18630002d134\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-10-04T17:23:22Z_36ac3680', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'logs/azureml/21_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/21_azureml.log?sv=2019-07-07&sr=b&sig=HfHkWgXkDMO3xhlByJgg91vZU6SIihR78X2cedHE1S8%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=sQ46DUXQ1Fau%2BRJmqKFYFvaClJOpKFsy%2FOgSO5aiddk%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=voYVjHL6oA4r17JyW1EMhfGkJ7PmbafH6oPsQvS6csQ%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=fkxB5cX119%2Bk46%2BY69Ug9rh%2BCre9SLHv%2BHFbOk%2FOGNc%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=SE8aTol8dt5XIOd7YR17VhAloGqFJ9P5UEe0LSqZ1uc%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=%2BSEyOvOBOo%2BMAxKxSJFQvsBGog47u3onz%2FN9fHZmdwg%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.7b51b10a-b11a-4d61-abb5-78f809f3eb1a/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=tAh%2FbzpOxb%2Bq1rfxtCr6biAh%2B5z8xpnDZruOSHGh1YA%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-14T23%3A56%3A54Z&ske=2021-11-16T08%3A06%3A54Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A34Z&se=2021-11-16T00%3A29%3A34Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 2821fae1-d158-4bf6-8c47-8c2ff5787eda\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/2821fae1-d158-4bf6-8c47-8c2ff5787eda?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Split  Raw Data ) Status: Running\n",
      "\n",
      "StepRun(Split  Raw Data) Execution Summary\n",
      "===========================================\n",
      "StepRun( Split  Raw Data ) Status: Finished\n",
      "\n",
      "Warnings:\n",
      "This run is using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"\n",
      "{'runId': '2821fae1-d158-4bf6-8c47-8c2ff5787eda', 'target': 'mm-cluster', 'status': 'Completed', 'startTimeUtc': '2021-11-15T16:29:42.909018Z', 'endTimeUtc': '2021-11-15T16:30:07.231316Z', 'services': {}, 'warnings': [{'message': 'This run is using a new job runtime with improved performance and error reporting. The logs from your script are in user_logs/std_log.txt. Please let us know if you run into any issues, and if you would like to opt-out, please add the environment variable AZUREML_COMPUTE_USE_COMMON_RUNTIME to the environment variables section of the job and set its value to the string \"false\"'}], 'properties': {'ContentSnapshotId': 'b18049c8-d927-4fae-bf3d-e95c40d4056e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '079abd42-3d10-40a6-9521-bbf3e3ebfbe8', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '94048c2f', 'azureml.pipelinerunid': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipeline': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '882a97b7-8f14-40c8-b924-1181eeae1977'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'Exp_Raw_Data', 'mechanism': 'Direct'}}], 'outputDatasets': [{'identifier': {'savedId': '4880359c-a860-4c1f-b948-e46f84a5a2c8', 'registeredId': 'fe5806d3-c9f2-467f-8704-830469d6b1f4', 'registeredVersion': '61'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'Exp_Training_Data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'exp_training_data/2821fae1-d158-4bf6-8c47-8c2ff5787eda')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"4880359c-a860-4c1f-b948-e46f84a5a2c8\",\n",
      "    \"name\": \"exp_Training_Data\",\n",
      "    \"version\": 61,\n",
      "    \"workspace\": \"Workspace.create(name='mm-aml-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-machine-learning-dev-rg')\"\n",
      "  }\n",
      "}}, {'identifier': {'savedId': 'bf49c400-7819-4da3-9eb0-eed19fada884', 'registeredId': '0ebfab22-bc0e-4065-9642-4a376d23c95b', 'registeredVersion': '61'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'Exp_Testing_Data'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'exp_testing_data/2821fae1-d158-4bf6-8c47-8c2ff5787eda')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"bf49c400-7819-4da3-9eb0-eed19fada884\",\n",
      "    \"name\": \"exp_Testing_Data\",\n",
      "    \"version\": 61,\n",
      "    \"workspace\": \"Workspace.create(name='mm-aml-dev', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-machine-learning-dev-rg')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'split.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--exp_training_data', 'DatasetOutputConfig:Exp_Training_Data', '--exp_testing_data', 'DatasetOutputConfig:Exp_Testing_Data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mm-cluster', 'dataReferences': {}, 'data': {'Exp_Raw_Data': {'dataLocation': {'dataset': {'id': '882a97b7-8f14-40c8-b924-1181eeae1977', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'Exp_Raw_Data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'Exp_Training_Data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'exp_training_data/{run-id}'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'exp_Training_Data', 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"5bf2ef2a-9ffe-42f3-8fff-b5c25e96dca4\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"6152d372-abab-4a8f-a109-aae2807fbb54\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}, 'Exp_Testing_Data': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': 'exp_testing_data/{run-id}'}, 'uri': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': 'exp_Testing_Data', 'description': None, 'tags': None, 'datasetRegistrationOptions': {'additionalTransformation': '{\\n  \"blocks\": [\\n    {\\n      \"id\": \"67c9e532-efa4-484a-9bf0-7209220c0228\",\\n      \"type\": \"Microsoft.DPrep.ParseDelimitedBlock\",\\n      \"arguments\": {\\n        \"columnHeadersMode\": 3,\\n        \"fileEncoding\": 0,\\n        \"handleQuotedLineBreaks\": false,\\n        \"preview\": false,\\n        \"separator\": \",\",\\n        \"skipRows\": 0,\\n        \"skipRowsMode\": 0\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    },\\n    {\\n      \"id\": \"c58f534f-06c3-4342-a7b7-5a392e7e578c\",\\n      \"type\": \"Microsoft.DPrep.DropColumnsBlock\",\\n      \"arguments\": {\\n        \"columns\": {\\n          \"type\": 0,\\n          \"details\": {\\n            \"selectedColumns\": [\\n              \"Path\"\\n            ]\\n          }\\n        }\\n      },\\n      \"localData\": {},\\n      \"isEnabled\": true,\\n      \"name\": null,\\n      \"annotation\": null\\n    }\\n  ],\\n  \"inspectors\": [],\\n  \"meta\": {\\n    \"steps_added\": \"2\"\\n  }\\n}'}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-10-04T17:23:22Z_36ac3680', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'logs/azureml/22_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/22_azureml.log?sv=2019-07-07&sr=b&sig=jn1h%2Fq2tkTggmVgGnGuOSPm%2Fuwa1DxL0%2F6vozID3eQM%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=%2B6mNuhvh6bqDBT59J%2BUb849g%2BPcC6TFvFxWi6wP8JiA%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=Lqp5F2Qw0lPVbWfSYEGvOaaqvtxneC74xbxE%2BE7b9Z8%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r', 'logs/azureml/dataprep/rslex.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/dataprep/rslex.log?sv=2019-07-07&sr=b&sig=dneaU0f%2BL2g7iU4G%2FnAoT0sCwQsRkM0ina%2FFptRnAcE%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=2AOPzRLLLUEUJxZq1yScQ2tr95rmL59JUuu6GZ%2BVbFY%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ra%2F2B%2FlbUW1ah3V16G3%2Bf4QFEiH9op8%2BQziUvJDlTK8%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.2821fae1-d158-4bf6-8c47-8c2ff5787eda/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ke%2BUf9wPOwMw5BHUZmBx6A2Yo%2FxwBa3iz2Ue9a0zcU8%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A06Z&se=2021-11-16T00%3A30%3A06Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/47c73f6f-9011-4fc6-bb29-fcf377d6be9b?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Train ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      "========================================================================================================================\n",
      "2021-11-15T16:30:23Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=367987 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-11-15T16:30:23Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore\n",
      "2021-11-15T16:30:24Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:30:24Z Starting output-watcher...\n",
      "2021-11-15T16:30:24Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-11-15T16:30:24Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2021-11-15T16:30:24Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_21ec214220b650a356d20fde58334d25\n",
      "Digest: sha256:6ab9323cb44918bdac4d534836922d8bdfce866084fdd749232e8a6845fe5b33\n",
      "Status: Image is up to date for 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25:latest\n",
      "7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25:latest\n",
      "2021-11-15T16:30:25Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:30:25Z Check if container 47c73f6f-9011-4fc6-bb29-fcf377d6be9b already exist exited with 0, \n",
      "\n",
      "6f79ba24ec308d64fb773a672d4481482c88c726eb9015e3913f4f4cc105412e\n",
      "2021-11-15T16:30:25Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-11-15T16:30:25Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-b940c5afe236e5bda1570bd0b23ddbc1-1ff7a8143c60ed64-01 -sshRequired=false] \n",
      "2021/11/15 16:30:25 Got JobInfoJson from env\n",
      "2021/11/15 16:30:25 Starting App Insight Logger for task:  containerSetup\n",
      "2021/11/15 16:30:25 Version: 3.0.01769.0004 Branch: 2021-11-05 Commit: a04a71b\n",
      "2021/11/15 16:30:25 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/11/15 16:30:25 Starting infiniband setup\n",
      "2021/11/15 16:30:25 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/11/15 16:30:25 Returning Python Version as 3.6\n",
      "2021-11-15T16:30:25Z VMSize: standard_d13, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021-11-15T16:30:25Z Not setting up Infiniband in Container\n",
      "2021/11/15 16:30:25 VMSize: standard_d13, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/11/15 16:30:25 VMSize: standard_d13, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/11/15 16:30:25 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/11/15 16:30:25 Not setting up Infiniband in Container\n",
      "2021/11/15 16:30:25 Not setting up Infiniband in Container\n",
      "2021/11/15 16:30:25 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/11/15 16:30:25 Returning Python Version as 3.6\n",
      "2021/11/15 16:30:25 sshd inside container not required for job, skipping setup.\n",
      "2021/11/15 16:30:26 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2021/11/15 16:30:26 App Insight Client has already been closed\n",
      "2021/11/15 16:30:26 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-11-15T16:30:26Z Starting docker container succeeded.\n",
      "2021-11-15T16:30:29Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:30:29Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:30:30Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2021/11/15 16:30:23 Got JobInfoJson from env\n",
      ">>>   2021/11/15 16:30:23 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/11/15 16:30:23 Version: 3.0.01769.0004 Branch: 2021-11-05 Commit: a04a71b\n",
      ">>>   2021/11/15 16:30:23 Got JobInfoJson from env\n",
      ">>>   2021/11/15 16:30:23 runtime.GOOS linux\n",
      ">>>   2021/11/15 16:30:23 Checking if '/tmp' exists\n",
      ">>>   2021/11/15 16:30:23 Reading dyanamic configs\n",
      ">>>   2021/11/15 16:30:23 Container sas url: https://baiscriptseastus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=0zSJlZiBvTfbGrZHmFBZqzDes0PMmYkeROmANx9hhuo%3D\n",
      ">>>   2021/11/15 16:30:23 Starting Azsecpack installation on machine: ee3f2eb74e18439d931007231a2709c9000001#72f988bf-86f1-41af-91ab-2d7cd011db47#5da07161-3770-4a4b-aa43-418cbbb627cf#mm-machine-learning-dev-rg#mm-aml-dev#mm-cluster#tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d\n",
      ">>>   2021/11/15 16:30:23 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n",
      ">>>   2021/11/15 16:30:23 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: true,\n",
      ">>>   2021/11/15 16:30:23 Is Azsecpack enabled: true, GetDisableVsatlsscan: true\n",
      ">>>   2021/11/15 16:30:23 Start preparing environment for azsecpack installation. MachineName is ee3f2eb74e18439d931007231a2709c9000001 \n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:23 \n",
      ">>>   2021/11/15 16:30:23 \n",
      ">>>   2021/11/15 16:30:23 bypass systemd resolved\n",
      ">>>   2021/11/15 16:30:23 Cluster Subscription Id: 5da07161-3770-4a4b-aa43-418cbbb627cf\n",
      ">>>   2021/11/15 16:30:23 Cluster Workspace Name: mm-aml-dev\n",
      ">>>   2021/11/15 16:30:23 Cluster Name: mm-cluster\n",
      ">>>   2021/11/15 16:30:23 VMsize: standard_d13\n",
      ">>>   2021/11/15 16:30:23 GPU Count: 0\n",
      ">>>   2021/11/15 16:30:23 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/11/15 16:30:23 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:23 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:23 Get GPU count failed with err: The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n",
      ">>>   2021/11/15 16:30:23 AMLComputeXDSEndpoint:  https://eastus2.cert.api.azureml.ms/xdsbatchai\n",
      ">>>   2021/11/15 16:30:23 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/11/15 16:30:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/config\n",
      ">>>   2021/11/15 16:30:23 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/11/15 16:30:23 Starting identity responder.\n",
      ">>>   2021/11/15 16:30:23 Starting identity responder.\n",
      ">>>   2021/11/15 16:30:23 Logfile used for identity responder: /mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/IdentityResponderLog-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      ">>>   2021/11/15 16:30:23 Logfile used for identity responder: /mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/IdentityResponderLog-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      ">>>   2021/11/15 16:30:23 Started Identity Responder for job.\n",
      ">>>   2021/11/15 16:30:23 Started Identity Responder for job.\n",
      ">>>   2021/11/15 16:30:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd\n",
      ">>>   2021/11/15 16:30:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/shared\n",
      ">>>   2021/11/15 16:30:23 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:23 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/11/15 16:30:23 Mounting job level file systems\n",
      ">>>   2021/11/15 16:30:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts\n",
      ">>>   2021/11/15 16:30:23 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/11/15 16:30:23 Datastore credentials file not found, skipping.\n",
      ">>>   2021/11/15 16:30:23 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/config/.master.runtimesastokens\n",
      ">>>   2021/11/15 16:30:23 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/11/15 16:30:23 NFS mount is not enabled\n",
      ">>>   2021/11/15 16:30:23 No Azure File Shares configured\n",
      ">>>   2021/11/15 16:30:23 Mounting blob file systems\n",
      ">>>   2021/11/15 16:30:23 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/11/15 16:30:23 Mounting azureml-blobstore-7b68fa5b-8a1f-4f8a-be3d-54389e9b015c container from mmamldev2875344614 account at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore\n",
      ">>>   2021/11/15 16:30:23 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/11/15 16:30:23 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/11/15 16:30:23 Blobfuse cache size set to 367987 MB.\n",
      ">>>   2021/11/15 16:30:23 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=367987 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/11/15 16:30:23 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore\n",
      ">>>   2021/11/15 16:30:23 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore\n",
      ">>>   2021/11/15 16:30:23 Successfully mounted azureml-blobstore-7b68fa5b-8a1f-4f8a-be3d-54389e9b015c container from mmamldev2875344614 account at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore\n",
      ">>>   2021/11/15 16:30:24 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 No unmanaged file systems configured\n",
      ">>>   2021/11/15 16:30:24 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:24 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:24 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/11/15 16:30:24 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs\n",
      ">>>   2021/11/15 16:30:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs/tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d\n",
      ">>>   2021/11/15 16:30:24 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs/tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      ">>>   2021/11/15 16:30:24 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs\n",
      ">>>   2021/11/15 16:30:24 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs\n",
      ">>>   2021/11/15 16:30:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs\n",
      ">>>   2021/11/15 16:30:24 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs/tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d\n",
      ">>>   2021/11/15 16:30:24 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs/tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      ">>>   2021/11/15 16:30:24 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs\n",
      ">>>   2021/11/15 16:30:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs\n",
      ">>>   2021/11/15 16:30:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/outputs\n",
      ">>>   2021/11/15 16:30:24 Starting output-watcher...\n",
      ">>>   2021/11/15 16:30:24 Single file input dataset is enabled.\n",
      ">>>   2021/11/15 16:30:24 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/15 16:30:24 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/15 16:30:24 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/15 16:30:24 Start to pulling docker image: 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25\n",
      ">>>   2021/11/15 16:30:24 Start pull docker image: 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io\n",
      ">>>   2021/11/15 16:30:24 Getting credentials for image 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25 with url 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io\n",
      ">>>   2021/11/15 16:30:24 Container registry is ACR.\n",
      ">>>   2021/11/15 16:30:24 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/11/15 16:30:24 Getting ACR Credentials from EMS for environment experiment_env:Autosave_2021-10-04T17:23:22Z_36ac3680\n",
      ">>>   2021/11/15 16:30:24 Requesting XDS for registry details.\n",
      ">>>   2021/11/15 16:30:24 Attempt 1 of http call to https://eastus2.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev/clusters/mm-cluster/nodes/tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d?api-version=2018-02-01\n",
      ">>>   2021/11/15 16:30:24 Got container registry details from credentials service for registry address: 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io.\n",
      ">>>   2021/11/15 16:30:24 Writing ACR Details to file...\n",
      ">>>   2021/11/15 16:30:24 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/11/15 16:30:24 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2021/11/15 16:30:24 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/11/15 16:30:24 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/11/15 16:30:24 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/11/15 16:30:24 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/11/15 16:30:24 EMS returned 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io for environment experiment_env\n",
      ">>>   2021/11/15 16:30:24 Save docker credentials for image 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25 in /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/docker_login_6628B86F88495108\n",
      ">>>   2021/11/15 16:30:24 Start login to the docker registry\n",
      ">>>   2021/11/15 16:30:24 Successfully logged into the docker registry.\n",
      ">>>   2021/11/15 16:30:24 Start run pull docker image command\n",
      ">>>   2021/11/15 16:30:25 Pull docker image succeeded.\n",
      ">>>   2021/11/15 16:30:25 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/docker_login_6628B86F88495108\n",
      ">>>   2021/11/15 16:30:25 Pull docker image time: 773.433105ms\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:25 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:25 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:25 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:25 Setting the memory limit for docker container to be 56009 MB\n",
      ">>>   2021/11/15 16:30:25 The env variable file size is 42354 bytes\n",
      ">>>   2021/11/15 16:30:25 Creating parent cgroup '47c73f6f-9011-4fc6-bb29-fcf377d6be9b' for Containers used in Job\n",
      ">>>   2021/11/15 16:30:25 Add parent cgroup '47c73f6f-9011-4fc6-bb29-fcf377d6be9b' to container '47c73f6f-9011-4fc6-bb29-fcf377d6be9b'\n",
      ">>>   2021/11/15 16:30:25 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/11/15 16:30:25 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,47c73f6f-9011-4fc6-bb29-fcf377d6be9b,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/certs:/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,56009m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd:/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b:/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/config/.batchai.envlist,--cgroup-parent=/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/,--shm-size,2g\n",
      ">>>   2021/11/15 16:30:25 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/11/15 16:30:25 the binding /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b:/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b \n",
      ">>>   2021/11/15 16:30:25 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,47c73f6f-9011-4fc6-bb29-fcf377d6be9b,-m,56009m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/config/.batchai.envlist,--cgroup-parent=/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b:/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b,-v,/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd:/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd,-v,/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/certs:/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/certs\n",
      ">>>   2021/11/15 16:30:25 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 47c73f6f-9011-4fc6-bb29-fcf377d6be9b -m 56009m -w /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/config/.batchai.envlist --cgroup-parent=/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b:/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b -v /mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd:/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd -v /mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/certs:/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/certs -d -it --privileged --net=host 7b68fa5b8a1f4f8abe3d54389e9b015c.azurecr.io/azureml/azureml_21ec214220b650a356d20fde58334d25\n",
      ">>>   2021/11/15 16:30:25 Check if container 47c73f6f-9011-4fc6-bb29-fcf377d6be9b already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:25 Check if container 47c73f6f-9011-4fc6-bb29-fcf377d6be9b already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:25 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/11/15 16:30:25 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/11/15 16:30:25 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-b940c5afe236e5bda1570bd0b23ddbc1-1ff7a8143c60ed64-01 -sshRequired=false] \n",
      ">>>   2021/11/15 16:30:25 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-b940c5afe236e5bda1570bd0b23ddbc1-1ff7a8143c60ed64-01 -sshRequired=false] \n",
      ">>>   2021/11/15 16:30:26 Container ssh is not required for job type.\n",
      ">>>   2021/11/15 16:30:26 Starting docker container succeeded.\n",
      ">>>   2021/11/15 16:30:26 Starting docker container succeeded.\n",
      ">>>   2021/11/15 16:30:26 Disk space after starting docker container: 376530MB\n",
      ">>>   2021/11/15 16:30:26 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/15 16:30:26 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/15 16:30:26 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/15 16:30:26 Begin execution of runSpecialJobTask\n",
      ">>>   2021/11/15 16:30:26 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n",
      ">>>   2021/11/15 16:30:26 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml-logs\n",
      ">>>   2021/11/15 16:30:26 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs\n",
      ">>>   2021/11/15 16:30:26 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"b18049c8-d927-4fae-bf3d-e95c40d4056e\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/15 16:30:26 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs/65_job_prep-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      ">>>   2021/11/15 16:30:26 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml_compute_logs/65_job_prep-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      ">>>   2021/11/15 16:30:26 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b;/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"b18049c8-d927-4fae-bf3d-e95c40d4056e\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/15 16:30:26 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/11/15 16:30:26 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-b940c5afe236e5bda1570bd0b23ddbc1-b18049c1e98a1439-01 -t 47c73f6f-9011-4fc6-bb29-fcf377d6be9b bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/30544c4a-9039-4da9-a5e6-60495bcc74f4/job-1/47c73f6f-9011-4fc6-b_254c4cdf-4b76-43c2-ae44-14ed20bc3e1f/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/wd/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b;/azureml-envs/azureml_0c5a9aa2def4b3c2501c1f40287a356b/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/mounts/workspaceblobstore/azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"b18049c8-d927-4fae-bf3d-e95c40d4056e\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/15 16:30:28 Attempt 1 of http call to https://eastus2.api.azureml.ms/history/v1.0/private/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/mm-machine-learning-dev-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-dev/runs/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/spans\n",
      ">>>   2021/11/15 16:30:29 containerName:47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:29 sidecar containerName:47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   2021/11/15 16:30:29 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:29 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:29 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:29 sidecar dockerLauncher:docker\n",
      ">>>   2021/11/15 16:30:29 sidecarContainerId:6f79ba24ec308d64fb773a672d4481482c88c726eb9015e3913f4f4cc105412e\n",
      ">>>   2021/11/15 16:30:29 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:29 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:29 The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/15 16:30:29 Docker logs for 47c73f6f-9011-4fc6-bb29-fcf377d6be9b\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:26.904229] Entering job preparation.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.737118] Starting job preparation.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.737153] Extracting the control code.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.737478] Starting extract_project.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.737517] Starting to extract zip file.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.760389] Finished extracting zip file.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.770355] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.770394] Start fetching snapshots.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.770428] Start fetching snapshot.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:28.770436] Retrieving project from snapshot: b18049c8-d927-4fae-bf3d-e95c40d4056e\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 47\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.055169] Finished fetching snapshot.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.055207] Finished fetching snapshots.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.055213] Finished extract_project.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.055315] Finished fetching and extracting the control code.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.059225] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.060593] Start run_history_prep.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.065402] Entering context manager injector.\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: Acquired lockfile /tmp/47c73f6f-9011-4fc6-bb29-fcf377d6be9b-datastore.lock to downloading input data references\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.453821] downloadDataStore completed\n",
      ">>>   2021/11/15 16:30:29 runSpecialJobTask: preparation: [2021-11-15T16:30:29.456543] Job preparation is complete.\n",
      ">>>   2021/11/15 16:30:29 DockerSideCarContainerLogs:\n",
      ">>>   \n",
      ">>>   2021/11/15 16:30:29 DockerSideCarContainerLogs End\n",
      ">>>   2021/11/15 16:30:29 Execution of runSpecialJobTask completed\n",
      ">>>   2021/11/15 16:30:29 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/11/15 16:30:29 Process Exiting with Code:  0\n",
      ">>>   2021/11/15 16:30:30 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      ">>>   \n",
      "2021-11-15T16:30:30Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:30:30Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:30:30Z 127.0.0.1 slots=8 max-slots=8\n",
      "2021-11-15T16:30:30Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      "===============================================================================================================\n",
      "[2021-11-15T16:30:49.031540] Entering job release\n",
      "[2021-11-15T16:30:49.791561] Starting job release\n",
      "[2021-11-15T16:30:49.792064] Logging experiment finalizing status in history service.\n",
      "[2021-11-15T16:30:49.792298] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 402\n",
      "[2021-11-15T16:30:49.792888] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-11-15T16:30:49.800620] job release stage : execute_job_release starting...\n",
      "[2021-11-15T16:30:49.801383] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-11-15T16:30:49.801423] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-11-15T16:30:49.802174] Entering context manager injector.\n",
      "[2021-11-15T16:30:49.820691] job release stage : upload_datastore completed...\n",
      "[2021-11-15T16:30:49.873354] job release stage : send_run_telemetry starting...\n",
      "[2021-11-15T16:30:49.893658] get vm size and vm region successfully.\n",
      "[2021-11-15T16:30:49.901253] get compute meta data successfully.\n",
      "[2021-11-15T16:30:50.014688] job release stage : execute_job_release completed...\n",
      "[2021-11-15T16:30:50.076189] post artifact meta request successfully.\n",
      "[2021-11-15T16:30:50.160795] upload compute record artifact successfully.\n",
      "[2021-11-15T16:30:50.160852] job release stage : send_run_telemetry completed...\n",
      "[2021-11-15T16:30:50.161105] Job release is complete\n",
      "\n",
      "StepRun(Train) Execution Summary\n",
      "=================================\n",
      "StepRun( Train ) Status: Finished\n",
      "{'runId': '47c73f6f-9011-4fc6-bb29-fcf377d6be9b', 'target': 'mm-cluster', 'status': 'Completed', 'startTimeUtc': '2021-11-15T16:30:22.228157Z', 'endTimeUtc': '2021-11-15T16:30:59.521905Z', 'services': {}, 'properties': {'ContentSnapshotId': 'b18049c8-d927-4fae-bf3d-e95c40d4056e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '706de45e-1c43-477b-a2ea-32427be37737', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'ebec4b1c', 'azureml.pipelinerunid': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipeline': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '4880359c-a860-4c1f-b948-e46f84a5a2c8'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'Exp_Training_Data', 'mechanism': 'Direct'}}, {'dataset': {'id': 'bf49c400-7819-4da3-9eb0-eed19fada884'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'Exp_Testing_Data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--exp_trained_model_pipeline_data', '$AZUREML_DATAREFERENCE_exp_trained_model_pipeline_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mm-cluster', 'dataReferences': {'exp_trained_model_pipeline_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/exp_trained_model_pipeline_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'Exp_Training_Data': {'dataLocation': {'dataset': {'id': '4880359c-a860-4c1f-b948-e46f84a5a2c8', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'Exp_Training_Data', 'pathOnCompute': None, 'overwrite': False, 'options': None}, 'Exp_Testing_Data': {'dataLocation': {'dataset': {'id': 'bf49c400-7819-4da3-9eb0-eed19fada884', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'Exp_Testing_Data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-10-04T17:23:22Z_36ac3680', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml-logs/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt?sv=2019-07-07&sr=b&sig=ix%2F5b%2BYHuVyDutom2kPIawnLgu%2FsJtHYFF%2Fg80lSKT0%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'azureml-logs/65_job_prep-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml-logs/65_job_prep-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt?sv=2019-07-07&sr=b&sig=mgUtoybT2DYXnjn8S12RIIvEexD4zNzR73f17SQse%2Fg%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'azureml-logs/75_job_post-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml-logs/75_job_post-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt?sv=2019-07-07&sr=b&sig=vis6bMTEzTeSCzmZCaoAWppmDe0cgvQ3u9bjS18YE0Q%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'azureml-logs/process_info.json': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=4EbBoYDVzmHjGvlXipDB3GhbDjtO4qVhaJBN0wMNLlE%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'azureml-logs/process_status.json': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=1O7mNaTbbkJzqKKnqZV6fs2r4nNyFes8sgo%2FJBfDMyM%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/99_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/99_azureml.log?sv=2019-07-07&sr=b&sig=7hAYucWW8Nm52Z19KzJw5Z9LVA6p0PhmPFMhnFTiRWg%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=QzQA2t1FuNHLEL88d2%2BLH11cX%2Bxzqo8UJbTncApzxCQ%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=kWN%2BR7vTZGxAtzFRhSSxMda3tJxZw09VGx2DUhOId7U%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=olsM8DjDy5DKBdhrK883FioqYvLVg3%2F2SXIetT%2FkHJs%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=nFWFtJjA2YlM3L9X%2Bvy%2Bm5FzmJT9gZS73S4%2BJ9PqVdg%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=7fcsjvfBCERWTCuoEFOqz5zZnLySfgW4yzNuKnjfC%2FI%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=w%2BUaJzQp2SXWkdYngCEvIjkOhgKxcpAzv5MOAVm3DrY%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.47c73f6f-9011-4fc6-bb29-fcf377d6be9b/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=cSv%2FPQKQfSTfl3t79qc%2BMhLxMjKGYiGBywW1aLPOyZI%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A20%3A51Z&se=2021-11-16T00%3A30%3A51Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 22bbca27-38ed-4b21-bb4d-99f37fe2c684\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/22bbca27-38ed-4b21-bb4d-99f37fe2c684?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "StepRun( Evaluate and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      "========================================================================================================================\n",
      "2021-11-15T16:31:11Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/22bbca27-38ed-4b21-bb4d-99f37fe2c684/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/22bbca27-38ed-4b21-bb4d-99f37fe2c684/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=367987 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/22bbca27-38ed-4b21-bb4d-99f37fe2c684/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-11-15T16:31:11Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mm-aml-dev/azureml/22bbca27-38ed-4b21-bb4d-99f37fe2c684/mounts/workspaceblobstore\n",
      "2021-11-15T16:31:11Z The vmsize standard_d13 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-15T16:31:11Z Starting output-watcher...\n",
      "2021-11-15T16:31:11Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt\n",
      "===============================================================================================================\n",
      "[2021-11-15T16:31:22.540978] Entering job release\n",
      "[2021-11-15T16:31:23.297295] Starting job release\n",
      "[2021-11-15T16:31:23.298178] Logging experiment finalizing status in history service.\n",
      "[2021-11-15T16:31:23.298420] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 144\n",
      "[2021-11-15T16:31:23.298709] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-11-15T16:31:23.299003] job release stage : execute_job_release starting...\n",
      "[2021-11-15T16:31:23.301664] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-11-15T16:31:23.301897] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-11-15T16:31:23.308756] Entering context manager injector.\n",
      "[2021-11-15T16:31:23.327587] job release stage : upload_datastore completed...\n",
      "[2021-11-15T16:31:23.385475] job release stage : send_run_telemetry starting...\n",
      "[2021-11-15T16:31:23.403350] get vm size and vm region successfully.\n",
      "[2021-11-15T16:31:23.412766] get compute meta data successfully.\n",
      "[2021-11-15T16:31:23.522932] job release stage : execute_job_release completed...\n",
      "[2021-11-15T16:31:23.656732] post artifact meta request successfully.\n",
      "[2021-11-15T16:31:23.684484] upload compute record artifact successfully.\n",
      "[2021-11-15T16:31:23.684530] job release stage : send_run_telemetry completed...\n",
      "[2021-11-15T16:31:23.684772] Job release is complete\n",
      "\n",
      "StepRun(Evaluate and Register Model) Execution Summary\n",
      "=======================================================\n",
      "StepRun( Evaluate and Register Model ) Status: Finished\n",
      "{'runId': '22bbca27-38ed-4b21-bb4d-99f37fe2c684', 'target': 'mm-cluster', 'status': 'Completed', 'startTimeUtc': '2021-11-15T16:31:10.603545Z', 'endTimeUtc': '2021-11-15T16:31:37.158283Z', 'services': {}, 'properties': {'ContentSnapshotId': 'b18049c8-d927-4fae-bf3d-e95c40d4056e', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c77d40b6-bbfe-4f5a-a5f8-0051af45ee09', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '79980463', 'azureml.pipelinerunid': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipeline': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'evaluate_and_register.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--exp_trained_model_pipeline_data', '$AZUREML_DATAREFERENCE_exp_trained_model_pipeline_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mm-cluster', 'dataReferences': {'exp_trained_model_pipeline_data': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/47c73f6f-9011-4fc6-bb29-fcf377d6be9b/exp_trained_model_pipeline_data', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'experiment_env', 'version': 'Autosave_2021-10-04T17:23:22Z_36ac3680', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip', {'pip': ['azureml-defaults', 'pyarrow']}], 'name': 'azureml_0c5a9aa2def4b3c2501c1f40287a356b'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'AISupercomputer.D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': [], 'dataBricks': {'workers': 0, 'minimumWorkerCount': 0, 'maxMumWorkerCount': 0, 'sparkVersion': '4.0.x-scala2.11', 'nodeTypeId': 'Standard_D3_v2', 'sparkConf': {}, 'sparkEnvVars': {}, 'instancePoolId': None, 'timeoutSeconds': 0, 'linkedADBWorkspaceMetadata': None, 'databrickResourceId': None}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/azureml-logs/55_azureml-execution-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt?sv=2019-07-07&sr=b&sig=xXm4o66y4XSy0tibPM0e6X9RlTm4g%2Fdi5yijmlI9y7E%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A20%3A09Z&ske=2021-11-17T00%3A30%3A09Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'azureml-logs/65_job_prep-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/azureml-logs/65_job_prep-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt?sv=2019-07-07&sr=b&sig=8iR%2FbahcGlXxnAnOKwLNAi2pKacJSszhCWJqdCxXNJw%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A20%3A09Z&ske=2021-11-17T00%3A30%3A09Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=aQu%2B5Jx11tkXC1t3CAASl5oUK42qmBiPp%2FLxmi9%2FOeM%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A20%3A09Z&ske=2021-11-17T00%3A30%3A09Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'azureml-logs/75_job_post-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/azureml-logs/75_job_post-tvmps_dc48b79de49137fb2e60627feaa083d01d10cdabc97eb170f32014216d0c74ea_d.txt?sv=2019-07-07&sr=b&sig=30azJNWSIZtj8oYMZvvj1Mj4ClUwas4FL4383ul0XSA%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A20%3A09Z&ske=2021-11-17T00%3A30%3A09Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'azureml-logs/process_info.json': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=7L4t5qGM7xOcT%2BeqWIUvBOwGr%2B0IulJ%2FQ1koc1Yc6qI%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A20%3A09Z&ske=2021-11-17T00%3A30%3A09Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'azureml-logs/process_status.json': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=13qobjGNbpvlx4M4QIAtfAdiwbq05JlCS3W7ZYrtwaM%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A20%3A09Z&ske=2021-11-17T00%3A30%3A09Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'logs/azureml/99_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/logs/azureml/99_azureml.log?sv=2019-07-07&sr=b&sig=Sj4J73O0F5%2B%2F9%2BmTH6ocNsIW7zH20SdnQYZ3ZGFxNpc%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=1GW%2FOhBE8SMRrXPNi4xb4G6D9iZ6i6%2FwI75iGxcfNyk%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=rwQhelhxPX6paGTXyMuTrUPvx3rvZXh5KraI3ZxGab8%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=wMwxjIOybwxQofM7jC3t7MzXRPvdhLp9Nr5OzVj3x6Y%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=oLCJctzZvFdL7bRDQWA9uHa0%2FI2EY95Vm7QRIwVSRAw%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.22bbca27-38ed-4b21-bb4d-99f37fe2c684/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=q%2BeovGt08n96KWL4Q%2FnN7oe0xu3kIpvZAH1n1ZqfvwA%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A21%3A27Z&se=2021-11-16T00%3A31%3A27Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'c650cf47-3924-41bf-863b-bb3fdabb8729', 'status': 'Completed', 'startTimeUtc': '2021-11-15T16:26:06.213074Z', 'endTimeUtc': '2021-11-15T16:31:37.706201Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.c650cf47-3924-41bf-863b-bb3fdabb8729/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=XcRFbtbTsPqRTiX9AQ9KcC8VJ%2BumliqzIMHb%2F7gxBQU%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A31Z&se=2021-11-16T00%3A29%3A31Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.c650cf47-3924-41bf-863b-bb3fdabb8729/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=0X%2FsiTMgNJCZW2%2BwpNuXj6q8vBdkInQOmC0Ukq5YxGw%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A31Z&se=2021-11-16T00%3A29%3A31Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mmamldev2875344614.blob.core.windows.net/azureml/ExperimentRun/dcid.c650cf47-3924-41bf-863b-bb3fdabb8729/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=zQMZto%2FfufrJJYjLrtTKvX6JL2zZc9MG7rYHMzvVFxE%3D&skoid=83ede2c4-cce0-410e-b16f-c02f7a05745f&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-11-15T16%3A16%3A07Z&ske=2021-11-17T00%3A26%3A07Z&sks=b&skv=2019-07-07&st=2021-11-15T16%3A19%3A31Z&se=2021-11-16T00%3A29%3A31Z&sp=r'}, 'submittedBy': 'Megan Masanz'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = Experiment(ws, 'sample-pipeline-run')\n",
    "run = experiment.submit(pipeline)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd3e6e",
   "metadata": {},
   "source": [
    "## Publish Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b821664",
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name = 'Diabetes Batch Prediction Pipeline',\n",
    "                                     description = 'Pipeline that generates batch predictions using a registered trained model.',\n",
    "                                     continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d17a5269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>Diabetes Batch Prediction Pipeline</td><td><a href=\"https://ml.azure.com/pipelines/fea4fbb0-b781-4e59-b984-bb856ad90396?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-machine-learning-dev-rg/workspaces/mm-aml-dev\" target=\"_blank\" rel=\"noopener\">fea4fbb0-b781-4e59-b984-bb856ad90396</a></td><td>Active</td><td><a href=\"https://eastus2.api.azureml.ms/pipelines/v1.0/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/mm-machine-learning-dev-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-dev/PipelineRuns/PipelineSubmit/fea4fbb0-b781-4e59-b984-bb856ad90396\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: Diabetes Batch Prediction Pipeline,\n",
       "Id: fea4fbb0-b781-4e59-b984-bb856ad90396,\n",
       "Status: Active,\n",
       "Endpoint: https://eastus2.api.azureml.ms/pipelines/v1.0/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourceGroups/mm-machine-learning-dev-rg/providers/Microsoft.MachineLearningServices/workspaces/mm-aml-dev/PipelineRuns/PipelineSubmit/fea4fbb0-b781-4e59-b984-bb856ad90396)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9591b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
