{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1482d0b",
   "metadata": {},
   "source": [
    "## MLOps with Azure ML Pipelines\n",
    "\n",
    "ML Pipeline - Training & Registration.  ML Pipelines can help you to build, optimize and manage your machine learning workflow. \n",
    "\n",
    "ML Pipelines encapsulate a workflow for a machine learning task.  Tasks often include:\n",
    "- Data Prep\n",
    "- Training \n",
    "- Publishing Models\n",
    "- Deployment of Models\n",
    "\n",
    "First we will set some key variables to be leveraged inside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bf1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"\")\n",
    "cluster_name = os.getenv(\"CLUSTER_NAME\", default=\"\")\n",
    "pipeline_name = os.getenv(\"PIPELINE_NAME\", default=\"\")\n",
    "model_name = os.getenv(\"MODEL_NAME\", default=\"\")\n",
    "build_id = os.getenv(\"BUILD_BUILDID\", default='1')\n",
    "\n",
    "print('subscription_id = ' + str(subscription_id))\n",
    "print('resource_group = ' + str(resource_group))\n",
    "print('workspace_name = ' + str(workspace_name))\n",
    "print('workspace_region = ' + str(workspace_region))\n",
    "print('cluster_name = ' + str(cluster_name))\n",
    "print('pipeline_name = ' + str(pipeline_name))\n",
    "print('model_name = ' + str(model_name))\n",
    "print('build_id=' + str(build_id))\n",
    "print('build_number = ' + build_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ed2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_env_name = \"experiment_env\"\n",
    "experiment_folder = 'exp_train_pipeline'\n",
    "dataset_prefix_name = 'exp'\n",
    "cluster_name = \"mm-cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23e496",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8006de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17a44c",
   "metadata": {},
   "source": [
    "### Connect to the workspace and create a cluster for running the AML Pipeline\n",
    "\n",
    "Connect to the AML workspace and the default datastore. To run an AML Pipeline, we will want to create compute if a compute cluster is not already available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f59e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "# Connect to AML Workspace\n",
    "#ws = Workspace.from_config()\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id=subscription_id, \n",
    "                   resource_group=resource_group, \n",
    "                   workspace_name=workspace_name)\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace does not exist. Creating workspace\")\n",
    "    ws = Workspace.create(name=workspace_name, subscription_id=subscription_id, resource_group=resource_group,\n",
    "                            location=workspace_region, create_resource_group=True, sku='enterprise', exist_ok=True)\n",
    "    \n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800a4a0",
   "metadata": {},
   "source": [
    "## Create Run configuration\n",
    "\n",
    "The RunConfiguration defines the environment used across all the python steps.  There are a variety of ways of setting up an environment.  An environment holds the required python packages needed for your code to execute on a compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142a17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp_train_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1da7b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda_yml_file = '../configuration/environment.yml'\n",
    "conda_yml_file = './'+ experiment_folder+ '/environment.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d32e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $conda_yml_file\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow\n",
    "  - azureml-monitoring\n",
    "  - azureml-interpret\n",
    "  - inference-schema\n",
    "  - joblib\n",
    "  - azure-ml-api-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b44524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "env = Environment.from_conda_specification(\"experiment_env\", conda_yml_file)\n",
    "\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.docker.use_docker = True\n",
    "run_config.environment = env\n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af1db661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment_env'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_env_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7778ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(registered_env_name, conda_yml_file)\n",
    "\n",
    "# Register the environment \n",
    "experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, registered_env_name)\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51624940",
   "metadata": {},
   "source": [
    "## Define Output datasets\n",
    "\n",
    "\n",
    "The **OutputFileDatasetConfig** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you need to pass it as a script argument so your code can access the datastore location referenced by the data reference. \n",
    "\n",
    "Note, in all cases we specify the datastore that should hold the datasets and whether they should be registered following step completion or not. This can optionally be disabled by removing the register_on_complete() call.\n",
    "\n",
    "These can be viewed in the Datasets tab directly in the AML Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20c4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data from storage location and save to exp_raw_data\n",
    "exp_raw_data       = OutputFileDatasetConfig(name='Exp_Raw_Data', destination=(default_ds, dataset_prefix_name + '_raw_data/{run-id}')).read_delimited_files().register_on_complete(name= dataset_prefix_name + '_Raw_Data')\n",
    "\n",
    "#data split into testing and training\n",
    "exp_training_data  = OutputFileDatasetConfig(name='Exp_Training_Data', destination=(default_ds, dataset_prefix_name + '_training_data/{run-id}')).read_delimited_files().register_on_complete(name=dataset_prefix_name + '_Training_Data')\n",
    "exp_testing_data   = OutputFileDatasetConfig(name='Exp_Testing_Data', destination=(default_ds, dataset_prefix_name + '_testing_data/{run-id}')).read_delimited_files().register_on_complete(name=dataset_prefix_name + '_Testing_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22765c",
   "metadata": {},
   "source": [
    "## Define Pipeline Data\n",
    "\n",
    "Data used in pipeline can be **produced by one step** and **consumed in another step** by providing a PipelineData object as an output of one step and an input of one or more subsequent steps\n",
    "\n",
    "This can be leveraged for moving a model from one step into another for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c62ebc",
   "metadata": {},
   "source": [
    "### Create Python Script Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd4fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_step = PythonScriptStep(\n",
    "    name='Get Data',\n",
    "    script_name='get_data.py',\n",
    "    arguments =['--exp_raw_data', exp_raw_data],\n",
    "    outputs=[exp_raw_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37944cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/get_data.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "#Parse input arguments\n",
    "#command-line parsing module \n",
    "parser = argparse.ArgumentParser(\"Get data from and register in AML workspace\")\n",
    "parser.add_argument('--exp_raw_data', dest='exp_raw_data', required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_raw_dataset = args.exp_raw_data\n",
    "\n",
    "#Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "#Connect to default data store\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "raw_df = tab_data_set.to_pandas_dataframe()\n",
    "\n",
    "#Make directory on mounted storage\n",
    "os.makedirs(exp_raw_dataset, exist_ok=True)\n",
    "\n",
    "#this will allow us to register the dataset on completion\n",
    "raw_df.to_csv(os.path.join(exp_raw_dataset, 'exp_raw_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba2388",
   "metadata": {},
   "source": [
    "### Split Data Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3159a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_scale_step = PythonScriptStep(\n",
    "    name='Split  Raw Data',\n",
    "    script_name='split.py',\n",
    "    arguments =['--exp_training_data', exp_training_data,\n",
    "                '--exp_testing_data', exp_testing_data],\n",
    "    inputs=[exp_raw_data.as_input(name='Exp_Raw_Data')],\n",
    "    outputs=[exp_training_data, exp_testing_data],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87df8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/split.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/split.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Split raw data into train/test and scale appropriately\")\n",
    "\n",
    "parser.add_argument('--exp_training_data', dest='exp_training_data', required=True)\n",
    "parser.add_argument('--exp_testing_data', dest='exp_testing_data', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_training_data = args.exp_training_data\n",
    "exp_testing_data = args.exp_testing_data\n",
    "\n",
    "\n",
    "#Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "# Read input dataset to pandas dataframe\n",
    "raw_datset = current_run.input_datasets['Exp_Raw_Data']\n",
    "raw_df = raw_datset.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "for col in raw_df.columns:\n",
    "    missing = raw_df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    if num_missing > 0:  \n",
    "        raw_df['quality_{}_ismissing'.format(col)] = missing\n",
    "\n",
    "\n",
    "print(raw_df.columns)\n",
    "\n",
    "#Split data into training set and test set\n",
    "df_train, df_test = train_test_split(raw_df, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save train data to both train and test (reflects the usage pattern in this sample. Note: test/train sets are typically distinct data).\n",
    "os.makedirs(exp_training_data, exist_ok=True)\n",
    "os.makedirs(exp_testing_data, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(os.path.join(exp_training_data, 'exp_training_data.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(exp_testing_data, 'exp_testing_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f0e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TrainingStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62d0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw data will be preprocessed and registered as train/test datasets\n",
    "\n",
    "model_file = PipelineData(name='model_file', datastore=default_ds)\n",
    "\n",
    "#by specifying as input, it does not need to be included in the arguments\n",
    "train_model_step = PythonScriptStep(\n",
    "    name='Train',\n",
    "    script_name='train.py',\n",
    "    arguments =['--model_file_output', model_file],\n",
    "    inputs=[\n",
    "            exp_training_data.as_input(name='Exp_Training_Data'),\n",
    "            exp_testing_data.as_input(name='Exp_Testing_Data'),\n",
    "           ],\n",
    "    outputs = [model_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8959aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/train.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Train Logistic Regression model\")\n",
    "parser.add_argument('--model_file_output', dest='model_file_output', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "model_file_output = args.model_file_output\n",
    "\n",
    "def converttypes(df):\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors = 'coerce')\n",
    "\n",
    "    print('data types')\n",
    "    print(df.dtypes)\n",
    "    return df\n",
    "\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "# Read input dataset to pandas dataframe\n",
    "X_train_dataset = run.input_datasets['Exp_Training_Data'].to_pandas_dataframe()\n",
    "X_test_dataset = run.input_datasets['Exp_Testing_Data'].to_pandas_dataframe()\n",
    "\n",
    "X_train_dataset = converttypes(X_train_dataset)\n",
    "X_test_dataset = converttypes(X_test_dataset)\n",
    "\n",
    "\n",
    "print(type(X_train_dataset))\n",
    "\n",
    "# Separate features and labels\n",
    "X_train, y_train = X_train_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_train_dataset['Diabetic'].values\n",
    "X_test, y_test   = X_test_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_test_dataset['Diabetic'].values\n",
    "\n",
    "print('***********')\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train[0]))\n",
    "print(type(y_test[0]))\n",
    "print('**********')\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "print('y_hat[0] is if type=:' + str(type(y_hat[0])))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "run.parent.log(name='AUC', value=np.float(auc))\n",
    "run.parent.log(name='Accuracy', value=np.float(acc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='./outputs/diabetes_model_remote.pkl')\n",
    "\n",
    "os.makedirs(model_file_output, exist_ok=True)\n",
    "\n",
    "shutil.copyfile('./outputs/diabetes_model_remote.pkl', os.path.join(model_file_output, 'diabetes_model_remote.pkl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84c9362",
   "metadata": {},
   "source": [
    "### Evaluate Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5c5b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate and register model here\n",
    "#Compare metrics from current model and register if better than current\n",
    "#best model\n",
    "\n",
    "\n",
    "deploy_file = PipelineData(name='deploy_file', datastore=default_ds)\n",
    "\n",
    "evaluate_and_register_step = PythonScriptStep(\n",
    "    name='Evaluate and Register Model',\n",
    "    script_name='evaluate_and_register.py',\n",
    "    arguments=[\n",
    "        '--model_file', model_file,\n",
    "        '--deploy_file_output', deploy_file,       \n",
    "    ],\n",
    "    inputs=[model_file.as_input('model_file'),\n",
    "            exp_training_data.as_input(name='Exp_Training_Data'),\n",
    "            exp_testing_data.as_input(name='Exp_Testing_Data')\n",
    "           ],\n",
    "    outputs=[ deploy_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e96bc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/evaluate_and_register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/evaluate_and_register.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "from azureml.interpret import ExplanationClient\n",
    "from azureml.interpret.scoring.scoring_explainer import LinearScoringExplainer, save\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "\n",
    "parser.add_argument('--model_file', type=str, required=True)\n",
    "parser.add_argument('--deploy_file_output', type=str, help='File passing in pipeline to deploy')\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "deploy_file = args.deploy_file_output\n",
    "model_file = args.model_file\n",
    "\n",
    "def converttypes(df):\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors = 'coerce')\n",
    "\n",
    "    print('data types')\n",
    "    print(df.dtypes)\n",
    "    return df\n",
    "\n",
    "def model_explain():\n",
    "    #load trinning data\n",
    "    X_train_dataset = run.input_datasets['Exp_Training_Data'].to_pandas_dataframe()\n",
    "    X_test_dataset = run.input_datasets['Exp_Testing_Data'].to_pandas_dataframe()\n",
    "    \n",
    "    X_test_dataset = converttypes(X_test_dataset)\n",
    "    X_train_dataset = converttypes(X_train_dataset)\n",
    "    \n",
    "    X_train, y_train = X_train_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_train_dataset['Diabetic'].values\n",
    "    X_test, y_test   = X_test_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_test_dataset['Diabetic'].values\n",
    "\n",
    "    \n",
    "    #load the model\n",
    "    model_list = Model.list(ws, name=model_name, latest=True)\n",
    "    model_path = model_list[0].download(exist_ok=True)\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    #https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/explain-model/azure-integration/scoring-time/train_explain.py\n",
    "    # create an explanation client to store the explanation (contrib API)\n",
    "    client = ExplanationClient.from_run(run)\n",
    "\n",
    "    # create an explainer to validate or debug the model\n",
    "    tabular_explainer = TabularExplainer(model,\n",
    "                                         initialization_examples=X_train,\n",
    "                                         features=['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age'],\n",
    "                                         classes=[0, 1])\n",
    "                                         #transformations=transformations)\n",
    "\n",
    "    # explain overall model predictions (global explanation)\n",
    "    # passing in test dataset for evaluation examples - note it must be a representative sample of the original data\n",
    "    # more data (e.g. x_train) will likely lead to higher accuracy, but at a time cost\n",
    "    global_explanation = tabular_explainer.explain_global(X_test)\n",
    "\n",
    "    # uploading model explanation data for storage or visualization\n",
    "    comment = 'Global explanation on classification model trained'\n",
    "    client.upload_model_explanation(global_explanation, comment=comment, model_id=model_reg.id)\n",
    "\n",
    "\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "current_model_AUC = float(metrics['AUC'])\n",
    "current_model_accuracy = float(metrics['Accuracy'])\n",
    "\n",
    "# Get current model from workspace\n",
    "model_name = 'diabetes_model_remote'\n",
    "model_description = 'Diabetes model remote'\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'AUC': current_model_AUC}\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "# Copy  training outputs to relative path for registration\n",
    "\n",
    "\n",
    "\n",
    "relative_model_path = 'outputs'\n",
    "run.upload_folder(name=relative_model_path, path=model_file)\n",
    "\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    model_reg = run.register_model(model_path='outputs/diabetes_model_remote.pkl', model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties={'AUC': current_model_AUC})\n",
    "\n",
    "    #model_explain()\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['AUC']) < current_model_AUC:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "\n",
    "        model_reg = run.register_model(model_path='outputs/diabetes_model_remote.pkl', model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties={'AUC': current_model_AUC, 'Accuracy': current_model_accuracy})\n",
    "\n",
    "        #model_explain()\n",
    "        \n",
    "        # Output accuracy to file\n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('deploy'))\n",
    "    \n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        \n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('no deployment'))\n",
    "            \n",
    "        run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c1d8c",
   "metadata": {},
   "source": [
    "### Deploy ACI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d9d39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "359a7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_deploy_pipeline_data = PipelineData(\n",
    "#         name='scoring_url_file', \n",
    "#         pipeline_output_name='scoring_url_file',\n",
    "#         datastore=default_ds,\n",
    "#         output_mode='mount',\n",
    "#         is_directory=False)\n",
    "\n",
    "scoring_file = PipelineData(name='scoring_file', datastore=default_ds)\n",
    "\n",
    "aci_service_name = 'diabetes-service-remote-training'\n",
    "registered_model_name = 'diabetes_model_remote'\n",
    "\n",
    "env_name = PipelineParameter(name='environment_name', default_value=registered_env_name)\n",
    "service_name = PipelineParameter(name='service_name', default_value=aci_service_name)\n",
    "model_name = PipelineParameter(name='model_name', default_value=registered_model_name)\n",
    "\n",
    "\n",
    "\n",
    "deploy_test = PythonScriptStep(\n",
    "    name='Deploy to ACI',\n",
    "    script_name='deployACI.py',\n",
    "    arguments=[\n",
    "        '--scoring_file_output', scoring_file,\n",
    "        '--deploy_file', deploy_file,\n",
    "        '--environment_name', env_name,\n",
    "        '--service_name', service_name,\n",
    "        '--model_name', model_name\n",
    "        \n",
    "    ],\n",
    "    inputs=[\n",
    "        deploy_file.as_input('deploy_file'),\n",
    "            \n",
    "    ],\n",
    "    outputs=[scoring_file],\n",
    "    compute_target=pipeline_cluster,\n",
    "    source_directory='./' + experiment_folder,\n",
    "    allow_reuse=False,\n",
    "    runconfig=pipeline_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f056c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/deployACI.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/deployACI.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Workspace, Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice, AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Deploy arg parser')\n",
    "parser.add_argument('--scoring_file_output', type=str, help='File storing the scoring url')\n",
    "parser.add_argument('--deploy_file', type=str, help='File storing if model should be deployed')\n",
    "parser.add_argument('--environment_name', type=str,help='Environment name')\n",
    "parser.add_argument('--service_name', type=str,help='service name')\n",
    "parser.add_argument('--model_name', type=str,help='model name')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "scoring_url_file = args.scoring_file_output\n",
    "deploy_file      = args.deploy_file\n",
    "environment_name = args.environment_name\n",
    "service_name     = args.service_name\n",
    "model_name       = args.model_name\n",
    "\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "model = Model(ws, model_name)\n",
    "env = Environment.get(ws, environment_name)\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
    "\n",
    "# Deploy model\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "            cpu_cores = 1, \n",
    "            memory_gb = 2, \n",
    "            tags = {'model': 'diabetes remote training'},\n",
    "            auth_enabled=True,\n",
    "            enable_app_insights=True,\n",
    "            collect_model_data=True)\n",
    "\n",
    "try:\n",
    "    service = Webservice(ws, name=service_name)\n",
    "    if service:\n",
    "        service.delete()\n",
    "except WebserviceException as e:\n",
    "         print()\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, aci_config)\n",
    "service.wait_for_deployment(True)\n",
    "    \n",
    "\n",
    "# Output scoring url\n",
    "print(service.scoring_uri)\n",
    "with open(scoring_url_file, 'w+') as f:\n",
    "    f.write(service.scoring_uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f7162a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./exp_train_pipeline/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/score.py\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "from azureml.monitoring import ModelDataCollector\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#version 2\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    #Print statement for appinsights custom traces:\n",
    "    print (\"model initialized\" + time.strftime(\"%H:%M:%S\"))\n",
    "    # Get the path to the deployed model file and load it\n",
    "    path = os.path.join(Model.get_model_path('diabetes_model_remote'))\n",
    "    \n",
    "    print(path)\n",
    "    model = joblib.load(path)\n",
    "\n",
    "    \n",
    "    global inputs_dc, prediction_dc\n",
    "    inputs_dc = ModelDataCollector(\"best_model\", designation=\"inputs\", feature_names=['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age'])\n",
    "    prediction_dc = ModelDataCollector(\"best_model\", designation=\"predictions\", feature_names=[\"Diabetic\"])\n",
    "\n",
    "\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        # Get the input data as a numpy array\n",
    "        #data = np.array(json.loads(raw_data)['data'])\n",
    "        # Get a prediction from the model\n",
    "        \n",
    "        json_data = json.loads(raw_data)\n",
    "        predictions = model.predict(json_data['data'])\n",
    "        print (\"Prediction created\" + time.strftime(\"%H:%M:%S\"))\n",
    "        # Get the corresponding classname for each prediction (0 or 1)\n",
    "        classnames = ['not-diabetic', 'diabetic']\n",
    "        predicted_classes = []\n",
    "        for prediction in predictions:\n",
    "            val = int(prediction)\n",
    "            predicted_classes.append(classnames[val])\n",
    "        # Return the predictions as JSON\n",
    "        \n",
    "         # Log the input and output data to appinsights:\n",
    "        info = {\n",
    "            \"input\": raw_data,\n",
    "            \"output\": predicted_classes\n",
    "            }\n",
    "        print(json.dumps(info))\n",
    "        \n",
    "        inputs_dc.collect(json_data['data']) #this call is saving our input data into Azure Blob\n",
    "        prediction_dc.collect(predicted_classes) #this call is saving our prediction data into Azure Blob\n",
    "\n",
    "        \n",
    "        return json.dumps(predicted_classes)\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        print (error + time.strftime(\"%H:%M:%S\"))\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115753b",
   "metadata": {},
   "source": [
    "## Create Pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e261a",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "Create an Azure ML Pipeline by specifying the steps to be executed. Note: based on the dataset dependencies between steps, exection occurs logically such that no step will execute unless all of the necessary input datasets have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "058aa1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[get_data_step, split_scale_step, train_model_step, evaluate_and_register_step, deploy_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7d2c85c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted PipelineRun 18ab20d5-6ff5-4421-8512-38894ae7ea0b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/18ab20d5-6ff5-4421-8512-38894ae7ea0b?wsid=/subscriptions/5da07161-3770-4a4b-aa43-418cbbb627cf/resourcegroups/mm-aml-dev-ops-rg/workspaces/mm-aml-dev-ops&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(ws, 'AML_Automation_RemotePipelineTraining')\n",
    "run = experiment.submit(pipeline)\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5fe72a",
   "metadata": {},
   "source": [
    "## Testing with downloaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c79ecfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(workspace=Workspace.create(name='mm-aml-dev-ops', subscription_id='5da07161-3770-4a4b-aa43-418cbbb627cf', resource_group='mm-aml-dev-ops-rg'), name=diabetes_model_remote, id=diabetes_model_remote:12, version=12, tags={'AUC': '0.8484934573859395'}, properties={'AUC': '0.8484934573859395', 'Accuracy': '0.774'})]\n",
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "['0']\n",
      "['not-diabetic']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "model_list = Model.list(ws, name='diabetes_model_remote', latest=True)\n",
    "#model_list = Model.list(ws, name='diabetes_model', latest=True)\n",
    "print(model_list)\n",
    "model_path = model_list[0].download(exist_ok=True)\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "#run for downloaded model\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "json_data = json.loads(input_json)\n",
    "results = model.predict(json_data['data'])\n",
    "print((results))\n",
    "\n",
    "classnames = ['not-diabetic', 'diabetic']\n",
    "predicted_classes = []\n",
    "for prediction in results:\n",
    "    val = int(prediction)\n",
    "    predicted_classes.append(classnames[val])\n",
    "\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92239a2b",
   "metadata": {},
   "source": [
    "## Testing with Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd0bb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "??Webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ccc251d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "http://79b57900-3ccf-4574-856e-27a162e85a03.eastus.azurecontainer.io/score\n",
      "1gzYOEwJN9qfhajdUbYbuxdg3y9lfQhQ\n",
      "{\"data\": [[2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]]}\n",
      "'list' object has no attribute 'tolist'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "def MakePrediction():\n",
    "    endpoint_url = url\n",
    "    x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "    input_json = json.dumps({\"data\": x_new})\n",
    "    print(input_json)\n",
    "    body = input_json\n",
    "    r = requests.post(endpoint_url, headers=headers, data=body)\n",
    "    return (r.json())\n",
    "\n",
    "#get service endpoint\n",
    "service = Webservice(workspace=ws, name='diabetes-service-remote-training')\n",
    "print(service.state)\n",
    "if service.state == 'Healthy':\n",
    "    url = service.scoring_uri\n",
    "    print(url)\n",
    "    api_key = service.get_keys()[0]\n",
    "    print(api_key)\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "    results = MakePrediction()\n",
    "    print(results)\n",
    "else:\n",
    "    print('Service must be in health state to make API call')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec6ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf5ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4df0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3bd3e6e",
   "metadata": {},
   "source": [
    "## Publish Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b821664",
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline.publish(name = 'Diabetes Training Pipeline',\n",
    "                                     description = 'Pipeline that generates batch predictions using a registered trained model.',\n",
    "                                     continue_on_step_failure = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9591b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "# # Submit the Pipeline every Monday at 00:00 UTC\n",
    "# recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
    "# weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
    "#                                   description=\"Based on time\",\n",
    "#                                   pipeline_id=published_pipeline.id, \n",
    "#                                   experiment_name='mslearn-diabetes-pipeline', \n",
    "#                                   recurrence=recurrence)\n",
    "# print('Pipeline scheduled.')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
