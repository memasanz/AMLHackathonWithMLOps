{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1482d0b",
   "metadata": {},
   "source": [
    "## MLOps with Azure ML Pipelines\n",
    "\n",
    "ML Pipeline - Write Scripts to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ed2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_env_name = \"experiment_env\"\n",
    "experiment_folder = 'devOps_train_pipeline'\n",
    "dataset_prefix_name = 'exp'\n",
    "cluster_name = \"mm-cluster\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23e496",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8006de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, DataFactoryCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter, PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.data.sql_data_reference import SqlDataReference\n",
    "from azureml.pipeline.steps import DataTransferStep\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f59e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "# Connect to AML Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "#Select AML Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "142a17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devOps_train_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1da7b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda_yml_file = '../configuration/environment.yml'\n",
    "conda_yml_file = './'+ experiment_folder+ '/environment.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62d32e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/environment.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $conda_yml_file\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow\n",
    "  - azureml-monitoring\n",
    "  - azureml-interpret\n",
    "  - inference-schema\n",
    "  - joblib\n",
    "  - azure-ml-api-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f37944cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/get_data.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "#Parse input arguments\n",
    "#command-line parsing module \n",
    "parser = argparse.ArgumentParser(\"Get data from and register in AML workspace\")\n",
    "parser.add_argument('--exp_raw_data', dest='exp_raw_data', required=True)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_raw_dataset = args.exp_raw_data\n",
    "\n",
    "#Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "#Connect to default data store\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "raw_df = tab_data_set.to_pandas_dataframe()\n",
    "\n",
    "#Make directory on mounted storage\n",
    "os.makedirs(exp_raw_dataset, exist_ok=True)\n",
    "\n",
    "#this will allow us to register the dataset on completion\n",
    "raw_df.to_csv(os.path.join(exp_raw_dataset, 'exp_raw_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87df8c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/split.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/split.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Split raw data into train/test and scale appropriately\")\n",
    "\n",
    "parser.add_argument('--exp_training_data', dest='exp_training_data', required=True)\n",
    "parser.add_argument('--exp_testing_data', dest='exp_testing_data', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "exp_training_data = args.exp_training_data\n",
    "exp_testing_data = args.exp_testing_data\n",
    "\n",
    "\n",
    "#Get current run\n",
    "current_run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = current_run.experiment.workspace\n",
    "\n",
    "# Read input dataset to pandas dataframe\n",
    "raw_datset = current_run.input_datasets['Exp_Raw_Data']\n",
    "raw_df = raw_datset.to_pandas_dataframe()\n",
    "\n",
    "\n",
    "for col in raw_df.columns:\n",
    "    missing = raw_df[col].isnull()\n",
    "    num_missing = np.sum(missing)\n",
    "    if num_missing > 0:  \n",
    "        raw_df['quality_{}_ismissing'.format(col)] = missing\n",
    "\n",
    "\n",
    "print(raw_df.columns)\n",
    "\n",
    "#Split data into training set and test set\n",
    "df_train, df_test = train_test_split(raw_df, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save train data to both train and test (reflects the usage pattern in this sample. Note: test/train sets are typically distinct data).\n",
    "os.makedirs(exp_training_data, exist_ok=True)\n",
    "os.makedirs(exp_testing_data, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(os.path.join(exp_training_data, 'exp_training_data.csv'), index=False)\n",
    "df_test.to_csv(os.path.join(exp_testing_data, 'exp_testing_data.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8959aef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/train.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "#Parse input arguments\n",
    "parser = argparse.ArgumentParser(\"Train Logistic Regression model\")\n",
    "parser.add_argument('--model_file_output', dest='model_file_output', required=True)\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "model_file_output = args.model_file_output\n",
    "\n",
    "def converttypes(df):\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors = 'coerce')\n",
    "\n",
    "    print('data types')\n",
    "    print(df.dtypes)\n",
    "    return df\n",
    "\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "# Read input dataset to pandas dataframe\n",
    "X_train_dataset = run.input_datasets['Exp_Training_Data'].to_pandas_dataframe()\n",
    "X_test_dataset = run.input_datasets['Exp_Testing_Data'].to_pandas_dataframe()\n",
    "\n",
    "X_train_dataset = converttypes(X_train_dataset)\n",
    "X_test_dataset = converttypes(X_test_dataset)\n",
    "\n",
    "\n",
    "print(type(X_train_dataset))\n",
    "\n",
    "# Separate features and labels\n",
    "X_train, y_train = X_train_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_train_dataset['Diabetic'].values\n",
    "X_test, y_test   = X_test_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_test_dataset['Diabetic'].values\n",
    "\n",
    "print('***********')\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train[0]))\n",
    "print(type(y_test[0]))\n",
    "print('**********')\n",
    "# Set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "print('y_hat[0] is if type=:' + str(type(y_hat[0])))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "run.parent.log(name='AUC', value=np.float(auc))\n",
    "run.parent.log(name='Accuracy', value=np.float(acc))\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='./outputs/diabetes_model_remote.pkl')\n",
    "\n",
    "os.makedirs(model_file_output, exist_ok=True)\n",
    "\n",
    "shutil.copyfile('./outputs/diabetes_model_remote.pkl', os.path.join(model_file_output, 'diabetes_model_remote.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e96bc0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/evaluate_and_register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/evaluate_and_register.py\n",
    "\n",
    "from azureml.core import Run, Workspace, Datastore, Dataset\n",
    "from azureml.core.model import Model\n",
    "from azureml.data.datapath import DataPath\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "from azureml.interpret import ExplanationClient\n",
    "from azureml.interpret.scoring.scoring_explainer import LinearScoringExplainer, save\n",
    "\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Evaluate model and register if more performant\")\n",
    "\n",
    "parser.add_argument('--model_file', type=str, required=True)\n",
    "parser.add_argument('--deploy_file_output', type=str, help='File passing in pipeline to deploy')\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "deploy_file = args.deploy_file_output\n",
    "model_file = args.model_file\n",
    "\n",
    "def converttypes(df):\n",
    "    cols = df.columns\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors = 'coerce')\n",
    "\n",
    "    print('data types')\n",
    "    print(df.dtypes)\n",
    "    return df\n",
    "\n",
    "def model_explain():\n",
    "    #load trinning data\n",
    "    X_train_dataset = run.input_datasets['Exp_Training_Data'].to_pandas_dataframe()\n",
    "    X_test_dataset = run.input_datasets['Exp_Testing_Data'].to_pandas_dataframe()\n",
    "    \n",
    "    X_test_dataset = converttypes(X_test_dataset)\n",
    "    X_train_dataset = converttypes(X_train_dataset)\n",
    "    \n",
    "    X_train, y_train = X_train_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_train_dataset['Diabetic'].values\n",
    "    X_test, y_test   = X_test_dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, X_test_dataset['Diabetic'].values\n",
    "\n",
    "    \n",
    "    #load the model\n",
    "    model_list = Model.list(ws, name=model_name, latest=True)\n",
    "    model_path = model_list[0].download(exist_ok=True)\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    #https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/explain-model/azure-integration/scoring-time/train_explain.py\n",
    "    # create an explanation client to store the explanation (contrib API)\n",
    "    client = ExplanationClient.from_run(run)\n",
    "\n",
    "    # create an explainer to validate or debug the model\n",
    "    tabular_explainer = TabularExplainer(model,\n",
    "                                         initialization_examples=X_train,\n",
    "                                         features=['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age'],\n",
    "                                         classes=[0, 1])\n",
    "                                         #transformations=transformations)\n",
    "\n",
    "    # explain overall model predictions (global explanation)\n",
    "    # passing in test dataset for evaluation examples - note it must be a representative sample of the original data\n",
    "    # more data (e.g. x_train) will likely lead to higher accuracy, but at a time cost\n",
    "    global_explanation = tabular_explainer.explain_global(X_test)\n",
    "\n",
    "    # uploading model explanation data for storage or visualization\n",
    "    comment = 'Global explanation on classification model trained'\n",
    "    client.upload_model_explanation(global_explanation, comment=comment, model_id=model_reg.id)\n",
    "\n",
    "\n",
    "\n",
    "#Get current run\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "#Get default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "\n",
    "\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.get_metrics()\n",
    "\n",
    "print('current run metrics')\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('parent run metrics')\n",
    "#Get metrics associated with current parent run\n",
    "metrics = run.parent.get_metrics()\n",
    "\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "\n",
    "current_model_AUC = float(metrics['AUC'])\n",
    "current_model_accuracy = float(metrics['Accuracy'])\n",
    "\n",
    "# Get current model from workspace\n",
    "model_name = 'diabetes_model_remote'\n",
    "model_description = 'Diabetes model remote'\n",
    "model_list = Model.list(ws, name=model_name, latest=True)\n",
    "first_registration = len(model_list)==0\n",
    "\n",
    "updated_tags = {'AUC': current_model_AUC}\n",
    "\n",
    "print('updated tags')\n",
    "print(updated_tags)\n",
    "\n",
    "# Copy  training outputs to relative path for registration\n",
    "\n",
    "\n",
    "\n",
    "relative_model_path = 'outputs'\n",
    "run.upload_folder(name=relative_model_path, path=model_file)\n",
    "\n",
    "\n",
    "\n",
    "#If no model exists register the current model\n",
    "if first_registration:\n",
    "    print('First model registration.')\n",
    "    model_reg = run.register_model(model_path='outputs/diabetes_model_remote.pkl', model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties={'AUC': current_model_AUC})\n",
    "\n",
    "    #model_explain()\n",
    "else:\n",
    "    #If a model has been registered previously, check to see if current model \n",
    "    #performs better. If so, register it.\n",
    "    print(dir(model_list[0]))\n",
    "    if float(model_list[0].tags['AUC']) < current_model_AUC:\n",
    "        print('New model performs better than existing model. Register it.')\n",
    "\n",
    "        model_reg = run.register_model(model_path='outputs/diabetes_model_remote.pkl', model_name=model_name,\n",
    "                   tags=updated_tags,\n",
    "                   properties={'AUC': current_model_AUC, 'Accuracy': current_model_accuracy})\n",
    "\n",
    "        #model_explain()\n",
    "        \n",
    "        # Output accuracy to file\n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('deploy'))\n",
    "    \n",
    "    else:\n",
    "        print('New model does not perform better than existing model. Cancel run.')\n",
    "        \n",
    "        with open(deploy_file, 'w+') as f:\n",
    "            f.write(('no deployment'))\n",
    "            \n",
    "        run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f056c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/deployACI.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/deployACI.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Workspace, Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice, AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Deploy arg parser')\n",
    "parser.add_argument('--scoring_file_output', type=str, help='File storing the scoring url')\n",
    "parser.add_argument('--deploy_file', type=str, help='File storing if model should be deployed')\n",
    "parser.add_argument('--environment_name', type=str,help='Environment name')\n",
    "parser.add_argument('--service_name', type=str,help='service name')\n",
    "parser.add_argument('--model_name', type=str,help='model name')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "scoring_url_file = args.scoring_file_output\n",
    "deploy_file      = args.deploy_file\n",
    "environment_name = args.environment_name\n",
    "service_name     = args.service_name\n",
    "model_name       = args.model_name\n",
    "\n",
    "\n",
    "run = Run.get_context()\n",
    "\n",
    "#Get associated AML workspace\n",
    "ws = run.experiment.workspace\n",
    "\n",
    "model = Model(ws, model_name)\n",
    "env = Environment.get(ws, environment_name)\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
    "\n",
    "# Deploy model\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "            cpu_cores = 1, \n",
    "            memory_gb = 2, \n",
    "            tags = {'model': 'diabetes remote training'},\n",
    "            auth_enabled=True,\n",
    "            enable_app_insights=True,\n",
    "            collect_model_data=True)\n",
    "\n",
    "try:\n",
    "    service = Webservice(ws, name=service_name)\n",
    "    if service:\n",
    "        service.delete()\n",
    "except WebserviceException as e:\n",
    "         print()\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, aci_config)\n",
    "service.wait_for_deployment(True)\n",
    "    \n",
    "\n",
    "# Output scoring url\n",
    "print(service.scoring_uri)\n",
    "with open(scoring_url_file, 'w+') as f:\n",
    "    f.write(service.scoring_uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f7162a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./devOps_train_pipeline/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./$experiment_folder/score.py\n",
    "\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "from azureml.monitoring import ModelDataCollector\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#version 2\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    #Print statement for appinsights custom traces:\n",
    "    print (\"model initialized\" + time.strftime(\"%H:%M:%S\"))\n",
    "    # Get the path to the deployed model file and load it\n",
    "    path = os.path.join(Model.get_model_path('diabetes_model_remote'))\n",
    "    \n",
    "    print(path)\n",
    "    model = joblib.load(path)\n",
    "\n",
    "    \n",
    "    global inputs_dc, prediction_dc\n",
    "    inputs_dc = ModelDataCollector(\"best_model\", designation=\"inputs\", feature_names=['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age'])\n",
    "    prediction_dc = ModelDataCollector(\"best_model\", designation=\"predictions\", feature_names=[\"Diabetic\"])\n",
    "\n",
    "\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        # Get the input data as a numpy array\n",
    "        #data = np.array(json.loads(raw_data)['data'])\n",
    "        # Get a prediction from the model\n",
    "        \n",
    "        json_data = json.loads(raw_data)\n",
    "        predictions = model.predict(json_data['data'])\n",
    "        print (\"Prediction created\" + time.strftime(\"%H:%M:%S\"))\n",
    "        # Get the corresponding classname for each prediction (0 or 1)\n",
    "        classnames = ['not-diabetic', 'diabetic']\n",
    "        predicted_classes = []\n",
    "        for prediction in predictions:\n",
    "            val = int(prediction)\n",
    "            predicted_classes.append(classnames[val])\n",
    "        # Return the predictions as JSON\n",
    "        \n",
    "         # Log the input and output data to appinsights:\n",
    "        info = {\n",
    "            \"input\": raw_data,\n",
    "            \"output\": predicted_classes\n",
    "            }\n",
    "        print(json.dumps(info))\n",
    "        \n",
    "        inputs_dc.collect(json_data['data']) #this call is saving our input data into Azure Blob\n",
    "        prediction_dc.collect(predicted_classes) #this call is saving our prediction data into Azure Blob\n",
    "\n",
    "        \n",
    "        return json.dumps(predicted_classes)\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        print (error + time.strftime(\"%H:%M:%S\"))\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b549cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
